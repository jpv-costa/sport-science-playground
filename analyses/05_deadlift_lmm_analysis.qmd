---
title: "Velocity Stop Tables for Deadlift Training"
subtitle: "LMM Analysis with Conformal Prediction Intervals"
author: "Deadlift Study Project"
date: today
format:
  html:
    toc: true
    toc-depth: 3
    code-fold: true
    code-summary: "Show code"
    theme: cosmo
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  fig.width = 10,
  fig.height = 6
)

# Load required packages
library(ggplot2)
library(knitr)

# Load results
results <- readRDS("../data/processed/deadlift_lmm_results.rds")
data <- results$data

# For comparison with Study 4
study4_results <- tryCatch({
  readRDS("../data/processed/deadlift_rir_velocity_results.rds")
}, error = function(e) NULL)
```

## Executive Summary

This analysis extends Study 4 (Deadlift RIR-Velocity Relationship) with **Linear Mixed Effects Models (LMM)** to:

1. **Test if load percentage matters** - Should we use one universal velocity table or load-specific tables?
2. **Generate practical velocity stop tables** - Velocity thresholds for training based on target RIR
3. **Provide prediction intervals** - Using conformal prediction for distribution-free coverage guarantees

**Key Finding**: `r if(results$load_importance_result$recommendation == "global") "Load percentage does NOT significantly affect the velocity-RIR relationship. A single global velocity table is recommended." else "Load percentage significantly affects velocity-RIR. Load-specific tables are recommended."`

## Why Linear Mixed Effects Models?

Our data has a **nested structure**:
- 19 participants
- Each tested on 2 days
- At 2 load levels (80%, 90%)
- Multiple repetitions per condition

Traditional regression would violate independence assumptions. LMM properly accounts for:

- **Between-participant variation** (random intercepts)
- **Participant-specific velocity-RIR slopes** (random slopes)
- **Repeated measures** within participants

## Model Building Strategy

We fit progressively complex models and compared them using:

- **AIC** (Akaike Information Criterion) - penalizes complexity less
- **BIC** (Bayesian Information Criterion) - penalizes complexity more
- **Bayes Factor** approximation via BIC difference
- **Likelihood Ratio Tests** for nested models

### Models Compared

```{r model-comparison-table}
#| label: tbl-models
#| tbl-cap: "Model Comparison"

comparison_df <- as.data.frame(results$model_comparison$comparison_table)

# Format for display
comparison_df$AIC <- round(comparison_df$AIC, 1)
comparison_df$BIC <- round(comparison_df$BIC, 1)
comparison_df$delta_AIC <- round(comparison_df$delta_AIC, 1)
comparison_df$delta_BIC <- round(comparison_df$delta_BIC, 1)
comparison_df$bayes_factor_approx <- round(comparison_df$bayes_factor_approx, 3)
comparison_df$R2_conditional <- round(comparison_df$R2_conditional, 3)

kable(comparison_df[, c("model", "AIC", "BIC", "delta_BIC", "bayes_factor_approx", "R2_conditional")],
      col.names = c("Model", "AIC", "BIC", "ΔBIC", "BF (approx)", "R² (cond)"))
```

**Best Model**: `r results$model_comparison$best_model_name` (lowest BIC)

### Bayes Factor Interpretation

| Bayes Factor | Evidence |
|--------------|----------|
| > 100 | Decisive for simpler model |
| 30-100 | Very strong for simpler |
| 10-30 | Strong for simpler |
| 3-10 | Moderate for simpler |
| 1-3 | Weak evidence |
| 1/3-1 | Weak for complex |
| < 1/3 | Evidence for complex |

## Does Load Percentage Matter?

This is the key question: **Can we use ONE universal velocity table regardless of whether the athlete is lifting 80% or 90% of 1RM?**

```{r load-test}
#| label: tbl-load-test
#| tbl-cap: "Load Percentage Importance Test"

load_test <- results$load_importance_test

test_df <- data.frame(
  Metric = c(
    "Likelihood Ratio Chi-squared",
    "Degrees of Freedom",
    "P-value",
    "Delta AIC",
    "Delta BIC",
    "Bayes Factor (simpler vs complex)",
    "Interpretation"
  ),
  Value = c(
    round(load_test$lrt_chisq, 3),
    load_test$lrt_df,
    sprintf("%.4f", load_test$lrt_p_value),
    round(load_test$delta_aic, 2),
    round(load_test$delta_bic, 2),
    round(load_test$bayes_factor, 3),
    load_test$bf_interpretation
  )
)

kable(test_df, col.names = c("", ""))
```

**Recommendation**: `r results$load_importance_result$recommendation` velocity table

```{r load-decision}
if (results$load_importance_result$recommendation == "global") {
  cat("**Conclusion**: Load percentage does NOT significantly affect the velocity-RIR relationship.\n\n")
  cat("This means coaches and athletes can use a SINGLE velocity table regardless of\n")
  cat("whether they're lifting at 80% or 90% 1RM. This simplifies training prescription.\n")
} else {
  cat("**Conclusion**: Load percentage DOES significantly affect the velocity-RIR relationship.\n\n")
  cat("Separate velocity targets should be used for different load percentages.\n")
}
```

## Model Diagnostics

Before trusting our model, we verify assumptions:

### Residual Normality

```{r qq-plot}
#| label: fig-qq
#| fig-cap: "Q-Q Plot of Residuals"

# Get residuals from diagnostics
residuals <- results$diagnostics_full$residuals
fitted <- results$diagnostics_full$fitted

# Q-Q plot data
n <- length(residuals)
theoretical <- qnorm(ppoints(n))
sample <- sort(residuals)

qq_df <- data.frame(theoretical = theoretical, sample = sample)

ggplot(qq_df, aes(x = theoretical, y = sample)) +
  geom_point(alpha = 0.5, color = "#2E86AB") +
  geom_abline(slope = sd(residuals), intercept = mean(residuals),
              color = "#E63946", linewidth = 1) +
  labs(
    x = "Theoretical Quantiles",
    y = "Sample Quantiles",
    title = "Q-Q Plot of Model Residuals"
  ) +
  theme_minimal()
```

**Normality Test**: `r results$diagnostics$normality_test$interpretation`

### Homoscedasticity

```{r residual-plot}
#| label: fig-residuals
#| fig-cap: "Residuals vs Fitted Values"

resid_df <- data.frame(fitted = fitted, residuals = residuals)

ggplot(resid_df, aes(x = fitted, y = residuals)) +
  geom_point(alpha = 0.4, color = "#2E86AB") +
  geom_hline(yintercept = 0, color = "#E63946", linewidth = 1, linetype = "dashed") +
  geom_smooth(method = "loess", se = FALSE, color = "#F77F00", linewidth = 0.8) +
  labs(
    x = "Fitted Values (m/s)",
    y = "Residuals (m/s)",
    title = "Residuals vs Fitted Values"
  ) +
  theme_minimal()
```

**Homoscedasticity**: `r results$diagnostics$homoscedasticity_test$interpretation`

## Fixed Effects

```{r fixed-effects}
#| label: tbl-fixed-effects
#| tbl-cap: "Fixed Effects Estimates"

fe <- results$fixed_effects
fe$estimate <- round(fe$estimate, 4)
fe$std_error <- round(fe$std_error, 4)
fe$t_value <- round(fe$t_value, 2)
fe$p_value <- ifelse(fe$p_value < 0.001, "<0.001", sprintf("%.4f", fe$p_value))

kable(fe[, c("term", "estimate", "std_error", "t_value", "p_value")],
      col.names = c("Term", "Estimate", "SE", "t", "p-value"))
```

**Interpretation**: The RIR coefficient shows that for each additional repetition in reserve, velocity increases by approximately `r round(results$fixed_effects$estimate[results$fixed_effects$term == "rir"], 3)` m/s.

## Velocity Stop Table

This is the practical output for coaches and athletes:

```{r velocity-table}
#| label: tbl-velocity-stop
#| tbl-cap: "Velocity Stop Table: Target velocities for each RIR level"

vt <- results$velocity_table$table

if ("load_percentage" %in% names(vt)) {
  # Load-specific table
  vt$velocity <- round(vt$velocity, 3)
  vt$lower_95 <- round(vt$lower_95, 3)
  vt$upper_95 <- round(vt$upper_95, 3)

  kable(vt[, c("rir", "load_percentage", "velocity", "lower_95", "upper_95")],
        col.names = c("RIR", "Load", "Velocity (m/s)", "Lower 95%", "Upper 95%"))
} else {
  # Global table
  vt$velocity <- round(vt$velocity, 3)
  vt$lower_95 <- round(vt$lower_95, 3)
  vt$upper_95 <- round(vt$upper_95, 3)

  kable(vt[, c("rir", "velocity", "lower_95", "upper_95")],
        col.names = c("RIR", "Velocity (m/s)", "Lower 95%", "Upper 95%"))
}
```

### How to Use This Table

1. **During training**: Monitor bar velocity in real-time
2. **Stop the set** when velocity drops to your target RIR threshold
3. **Example**: To leave 2 reps in reserve, stop when velocity reaches ~`r round(results$velocity_table$table$velocity[results$velocity_table$table$rir == 2][1], 2)` m/s

### Visualization

```{r velocity-viz}
#| label: fig-velocity-table
#| fig-cap: "Velocity Stop Thresholds by RIR"

vt <- results$velocity_table$table

if ("load_percentage" %in% names(vt)) {
  ggplot(vt, aes(x = rir, y = velocity, color = load_percentage)) +
    geom_line(linewidth = 1.2) +
    geom_point(size = 3) +
    geom_ribbon(aes(ymin = lower_95, ymax = upper_95, fill = load_percentage),
                alpha = 0.2, color = NA) +
    scale_color_manual(values = c("80%" = "#E69F00", "90%" = "#009E73")) +
    scale_fill_manual(values = c("80%" = "#E69F00", "90%" = "#009E73")) +
    labs(
      x = "Repetitions in Reserve (RIR)",
      y = "Mean Velocity (m/s)",
      color = "Load",
      fill = "Load"
    ) +
    theme_minimal() +
    theme(legend.position = "bottom")
} else {
  ggplot(vt, aes(x = rir, y = velocity)) +
    geom_line(linewidth = 1.2, color = "#2E86AB") +
    geom_point(size = 3, color = "#2E86AB") +
    geom_ribbon(aes(ymin = lower_95, ymax = upper_95),
                alpha = 0.2, fill = "#2E86AB") +
    labs(
      x = "Repetitions in Reserve (RIR)",
      y = "Mean Velocity (m/s)",
      title = "Global Velocity Stop Table for Deadlift"
    ) +
    theme_minimal()
}
```

## General vs Individual Tables

Should athletes use the **general table** or create their own **individual calibration**?

```{r individual-comparison}
#| label: tbl-individual-comparison
#| tbl-cap: "General vs Individual Table Accuracy"

ic <- results$individual_comparison

comparison_df <- data.frame(
  Approach = c("General (Population)", "Individual (Calibrated)"),
  MAE = c(round(ic$global_mae * 1000, 2), round(ic$individual_mae * 1000, 2)),
  RMSE = c(round(ic$global_rmse * 1000, 2), round(ic$individual_rmse * 1000, 2))
)

kable(comparison_df,
      col.names = c("Approach", "MAE (mm/s)", "RMSE (mm/s)"))
```

**Improvement from individualization**: `r round(results$individual_comparison$mae_improvement_pct, 1)`%

**Recommendation**: `r results$individual_comparison$recommendation`

## Conformal Prediction Intervals

Traditional prediction intervals assume normality. **Conformal prediction** provides **distribution-free** intervals with guaranteed coverage.

### Method

1. Split data: Day 1 (calibration), Day 2 (test)
2. Calculate nonconformity scores (absolute residuals) on calibration set
3. Find the `r sprintf("%.0f", (1 - 0.05) * 100)`th percentile of scores
4. Use this to construct intervals on new data

### Results

```{r conformal-results}
#| label: tbl-conformal
#| tbl-cap: "Conformal vs Parametric Prediction Intervals"

conf <- results$conformal

comparison_df <- data.frame(
  Metric = c("Target Coverage", "Empirical Coverage", "Average Interval Width"),
  Parametric = c(
    "95%",
    sprintf("%.1f%%", conf$comparison$parametric_coverage * 100),
    sprintf("%.4f m/s", conf$comparison$parametric_width)
  ),
  Conformal = c(
    "95%",
    sprintf("%.1f%%", conf$comparison$conformal_coverage * 100),
    sprintf("%.4f m/s", conf$comparison$conformal_width)
  )
)

kable(comparison_df, col.names = c("Metric", "Parametric", "Conformal"))
```

**Key Insight**:

- Parametric coverage: `r sprintf("%.1f%%", results$conformal$comparison$parametric_coverage * 100)` (deviation from 95%: `r sprintf("%.1f%%", abs(results$conformal$comparison$parametric_coverage - 0.95) * 100)`)
- Conformal coverage: `r sprintf("%.1f%%", results$conformal$comparison$conformal_coverage * 100)` (deviation from 95%: `r sprintf("%.1f%%", abs(results$conformal$comparison$conformal_coverage - 0.95) * 100)`)

```{r conformal-recommendation}
if (abs(results$conformal$comparison$conformal_coverage - 0.95) <
    abs(results$conformal$comparison$parametric_coverage - 0.95)) {
  cat("Conformal intervals achieve coverage closer to the 95% target.\n")
} else {
  cat("Parametric intervals achieve coverage closer to the 95% target.\n")
}
```

## Practical Implications

### For Coaches and Athletes

1. **Use velocity monitoring** during deadlift sets
2. **Reference the velocity table** to estimate RIR in real-time
3. **Consider individual calibration** for serious athletes (if improvement >10%)
4. **Account for uncertainty**: Velocity estimates have ~`r round(results$conformal$interval_width * 1000, 1)` mm/s margin of error

### For Researchers

1. **LMM is appropriate** for this nested data structure
2. **Model assumptions are `r if(results$diagnostics$normality_test$is_normal && results$diagnostics$homoscedasticity_test$is_homoscedastic) "met" else "questionable - interpret with caution"`**
3. **Conformal prediction** provides more reliable coverage guarantees

## Limitations

1. **Sample size**: 19 participants (adequate for LMM but limits generalizability)
2. **Load range**: Only 80% and 90% tested
3. **Exercise specificity**: Results apply to conventional deadlift only
4. **Equipment**: Specific velocity measurement device used

## Conclusions

1. **`r if(results$load_importance_result$recommendation == "global") "A single global velocity table is sufficient" else "Load-specific tables are recommended"`** - load percentage `r if(results$load_importance_result$recommendation == "global") "does not significantly" else "significantly"` affect the velocity-RIR relationship

2. **Individual calibration improves accuracy** by `r round(results$individual_comparison$mae_improvement_pct, 1)`%

3. **Conformal prediction** provides more reliable interval coverage than parametric methods

4. **Velocity-based training** can effectively prescribe training intensity for deadlifts using the provided stop tables

## Technical Notes

This analysis used:
- **R6 classes** following SOLID principles
- **lme4** for Linear Mixed Effects Models
- **Split conformal prediction** for distribution-free intervals
- **BIC-based Bayes Factor approximation** for model comparison

## References

This methodology follows:

Nakagawa, S., & Schielzeth, H. (2013). A general and simple method for obtaining R² from generalized linear mixed-effects models. *Methods in Ecology and Evolution*, 4(2), 133-142.

Lei, J., G'Sell, M., Rinaldo, A., Tibshirani, R. J., & Wasserman, L. (2018). Distribution-Free Predictive Inference for Regression. *Journal of the American Statistical Association*, 113(523), 1094-1111.

Jukic, I., Prnjak, K., Helms, E. R., & McGuigan, M. R. (2024). Modeling the repetitions-in-reserve-velocity relationship. *Experimental Physiology*, 109(2), 193-206.
