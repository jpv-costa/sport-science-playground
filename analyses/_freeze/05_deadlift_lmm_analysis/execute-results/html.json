{
  "hash": "0722a8897084f55ed90c9c277edaca16",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Velocity Stop Tables for Deadlift Training\"\nsubtitle: \"LMM Analysis with Conformal Prediction Intervals\"\nauthor: \"Deadlift Study Project\"\ndate: today\nformat:\n  html:\n    toc: true\n    toc-depth: 3\n    code-fold: true\n    code-summary: \"Show code\"\n    theme: cosmo\nbibliography: references.bib\n---\n\n\n\n\n## Executive Summary\n\nThis analysis extends Study 4 (Deadlift RIR-Velocity Relationship) with **Linear Mixed Effects Models (LMM)** to:\n\n1. **Test if load percentage matters** - Should we use one universal velocity table or load-specific tables?\n2. **Generate practical velocity stop tables** - Velocity thresholds for training based on target RIR\n3. **Provide prediction intervals** - Using conformal prediction for distribution-free coverage guarantees\n\n**Key Finding**: Load percentage does NOT significantly affect the velocity-RIR relationship. A single global velocity table is recommended.\n\n## Why Linear Mixed Effects Models?\n\nOur data has a **nested structure**:\n- 19 participants\n- Each tested on 2 days\n- At 2 load levels (80%, 90%)\n- Multiple repetitions per condition\n\nTraditional regression would violate independence assumptions. LMM properly accounts for:\n\n- **Between-participant variation** (random intercepts)\n- **Participant-specific velocity-RIR slopes** (random slopes)\n- **Repeated measures** within participants\n\n## Model Building Strategy\n\nWe fit progressively complex models and compared them using:\n\n- **AIC** (Akaike Information Criterion) - penalizes complexity less\n- **BIC** (Bayesian Information Criterion) - penalizes complexity more\n- **Bayes Factor** approximation via BIC difference\n- **Likelihood Ratio Tests** for nested models\n\n### Models Compared\n\n\n::: {#tbl-models .cell tbl-cap='Model Comparison'}\n\n```{.r .cell-code}\ncomparison_df <- as.data.frame(results$model_comparison$comparison_table)\n\n# Format for display\ncomparison_df$AIC <- round(comparison_df$AIC, 1)\ncomparison_df$BIC <- round(comparison_df$BIC, 1)\ncomparison_df$delta_AIC <- round(comparison_df$delta_AIC, 1)\ncomparison_df$delta_BIC <- round(comparison_df$delta_BIC, 1)\ncomparison_df$bayes_factor_approx <- round(comparison_df$bayes_factor_approx, 3)\ncomparison_df$R2_conditional <- round(comparison_df$R2_conditional, 3)\n\nkable(comparison_df[, c(\"model\", \"AIC\", \"BIC\", \"delta_BIC\", \"bayes_factor_approx\", \"R2_conditional\")],\n      col.names = c(\"Model\", \"AIC\", \"BIC\", \"ΔBIC\", \"BF (approx)\", \"R² (cond)\"))\n```\n\n::: {.cell-output-display}\n\n\n|Model        |     AIC|     BIC| ΔBIC| BF (approx)| R² (cond)|\n|:------------|-------:|-------:|----:|-----------:|---------:|\n|base         | -1046.7| -1030.7| 54.6|       0.000|     0.616|\n|random_slope | -1109.3| -1085.2|  0.0|       1.000|     0.639|\n|with_load    | -1101.1| -1073.1| 12.1|       0.002|     0.639|\n|with_day     | -1091.5| -1059.4| 25.8|       0.000|     0.639|\n|interaction  | -1105.6| -1073.6| 11.7|       0.003|     0.654|\n|full         | -1081.3| -1037.2| 48.0|       0.000|     0.658|\n\n\n:::\n:::\n\n\n**Best Model**: random_slope (lowest BIC)\n\n### Bayes Factor Interpretation\n\n| Bayes Factor | Evidence |\n|--------------|----------|\n| > 100 | Decisive for simpler model |\n| 30-100 | Very strong for simpler |\n| 10-30 | Strong for simpler |\n| 3-10 | Moderate for simpler |\n| 1-3 | Weak evidence |\n| 1/3-1 | Weak for complex |\n| < 1/3 | Evidence for complex |\n\n## Does Load Percentage Matter?\n\nThis is the key question: **Can we use ONE universal velocity table regardless of whether the athlete is lifting 80% or 90% of 1RM?**\n\n\n::: {#tbl-load-test .cell tbl-cap='Load Percentage Importance Test'}\n\n```{.r .cell-code}\nload_test <- results$load_importance_test\n\ntest_df <- data.frame(\n  Metric = c(\n    \"Likelihood Ratio Chi-squared\",\n    \"Degrees of Freedom\",\n    \"P-value\",\n    \"Delta AIC\",\n    \"Delta BIC\",\n    \"Bayes Factor (simpler vs complex)\",\n    \"Interpretation\"\n  ),\n  Value = c(\n    round(load_test$lrt_chisq, 3),\n    load_test$lrt_df,\n    sprintf(\"%.4f\", load_test$lrt_p_value),\n    round(load_test$delta_aic, 2),\n    round(load_test$delta_bic, 2),\n    round(load_test$bayes_factor, 3),\n    load_test$bf_interpretation\n  )\n)\n\nkable(test_df, col.names = c(\"\", \"\"))\n```\n\n::: {.cell-output-display}\n\n\n|                                  |                                    |\n|:---------------------------------|:-----------------------------------|\n|Likelihood Ratio Chi-squared      |2.298                               |\n|Degrees of Freedom                |1                                   |\n|P-value                           |0.1295                              |\n|Delta AIC                         |0.3                                 |\n|Delta BIC                         |-3.71                               |\n|Bayes Factor (simpler vs complex) |0.157                               |\n|Interpretation                    |Moderate evidence for complex model |\n\n\n:::\n:::\n\n\n**Recommendation**: global velocity table\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (results$load_importance_result$recommendation == \"global\") {\n  cat(\"**Conclusion**: Load percentage does NOT significantly affect the velocity-RIR relationship.\\n\\n\")\n  cat(\"This means coaches and athletes can use a SINGLE velocity table regardless of\\n\")\n  cat(\"whether they're lifting at 80% or 90% 1RM. This simplifies training prescription.\\n\")\n} else {\n  cat(\"**Conclusion**: Load percentage DOES significantly affect the velocity-RIR relationship.\\n\\n\")\n  cat(\"Separate velocity targets should be used for different load percentages.\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n**Conclusion**: Load percentage does NOT significantly affect the velocity-RIR relationship.\n\nThis means coaches and athletes can use a SINGLE velocity table regardless of\nwhether they're lifting at 80% or 90% 1RM. This simplifies training prescription.\n```\n\n\n:::\n:::\n\n\n## Model Diagnostics\n\nBefore trusting our model, we verify assumptions:\n\n### Residual Normality\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get residuals from diagnostics\nresiduals <- results$diagnostics_full$residuals\nfitted <- results$diagnostics_full$fitted\n\n# Q-Q plot data\nn <- length(residuals)\ntheoretical <- qnorm(ppoints(n))\nsample <- sort(residuals)\n\nqq_df <- data.frame(theoretical = theoretical, sample = sample)\n\nggplot(qq_df, aes(x = theoretical, y = sample)) +\n  geom_point(alpha = 0.5, color = \"#2E86AB\") +\n  geom_abline(slope = sd(residuals), intercept = mean(residuals),\n              color = \"#E63946\", linewidth = 1) +\n  labs(\n    x = \"Theoretical Quantiles\",\n    y = \"Sample Quantiles\",\n    title = \"Q-Q Plot of Model Residuals\"\n  ) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![Q-Q Plot of Residuals](05_deadlift_lmm_analysis_files/figure-html/fig-qq-1.png){#fig-qq width=960}\n:::\n:::\n\n\n**Normality Test**: Residuals may deviate from normality (p < 0.05)\n\n### Homoscedasticity\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresid_df <- data.frame(fitted = fitted, residuals = residuals)\n\nggplot(resid_df, aes(x = fitted, y = residuals)) +\n  geom_point(alpha = 0.4, color = \"#2E86AB\") +\n  geom_hline(yintercept = 0, color = \"#E63946\", linewidth = 1, linetype = \"dashed\") +\n  geom_smooth(method = \"loess\", se = FALSE, color = \"#F77F00\", linewidth = 0.8) +\n  labs(\n    x = \"Fitted Values (m/s)\",\n    y = \"Residuals (m/s)\",\n    title = \"Residuals vs Fitted Values\"\n  ) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![Residuals vs Fitted Values](05_deadlift_lmm_analysis_files/figure-html/fig-residuals-1.png){#fig-residuals width=960}\n:::\n:::\n\n\n**Homoscedasticity**: Residuals show correlation with fitted values (r = 0.266), potential heteroscedasticity\n\n## Fixed Effects\n\n\n::: {#tbl-fixed-effects .cell tbl-cap='Fixed Effects Estimates'}\n\n```{.r .cell-code}\nfe <- results$fixed_effects\nfe$estimate <- round(fe$estimate, 4)\nfe$std_error <- round(fe$std_error, 4)\nfe$t_value <- round(fe$t_value, 2)\nfe$p_value <- ifelse(fe$p_value < 0.001, \"<0.001\", sprintf(\"%.4f\", fe$p_value))\n\nkable(fe[, c(\"term\", \"estimate\", \"std_error\", \"t_value\", \"p_value\")],\n      col.names = c(\"Term\", \"Estimate\", \"SE\", \"t\", \"p-value\"))\n```\n\n::: {.cell-output-display}\n\n\n|Term        | Estimate|     SE|     t|p-value |\n|:-----------|--------:|------:|-----:|:-------|\n|(Intercept) |   0.2152| 0.0098| 22.00|NA      |\n|rir         |   0.0292| 0.0035|  8.39|NA      |\n\n\n:::\n:::\n\n\n**Interpretation**: The RIR coefficient shows that for each additional repetition in reserve, velocity increases by approximately 0.029 m/s.\n\n## Velocity Stop Table\n\nThis is the practical output for coaches and athletes:\n\n\n::: {#tbl-velocity-stop .cell tbl-cap='Velocity Stop Table: Target velocities for each RIR level'}\n\n```{.r .cell-code}\nvt <- results$velocity_table$table\n\nif (\"load_percentage\" %in% names(vt)) {\n  # Load-specific table\n  vt$velocity <- round(vt$velocity, 3)\n  vt$lower_95 <- round(vt$lower_95, 3)\n  vt$upper_95 <- round(vt$upper_95, 3)\n\n  kable(vt[, c(\"rir\", \"load_percentage\", \"velocity\", \"lower_95\", \"upper_95\")],\n        col.names = c(\"RIR\", \"Load\", \"Velocity (m/s)\", \"Lower 95%\", \"Upper 95%\"))\n} else {\n  # Global table\n  vt$velocity <- round(vt$velocity, 3)\n  vt$lower_95 <- round(vt$lower_95, 3)\n  vt$upper_95 <- round(vt$upper_95, 3)\n\n  kable(vt[, c(\"rir\", \"velocity\", \"lower_95\", \"upper_95\")],\n        col.names = c(\"RIR\", \"Velocity (m/s)\", \"Lower 95%\", \"Upper 95%\"))\n}\n```\n\n::: {.cell-output-display}\n\n\n| RIR| Velocity (m/s)| Lower 95%| Upper 95%|\n|---:|--------------:|---------:|---------:|\n|   0|          0.215|     0.114|     0.317|\n|   1|          0.244|     0.143|     0.346|\n|   2|          0.274|     0.172|     0.375|\n|   3|          0.303|     0.201|     0.404|\n|   4|          0.332|     0.231|     0.433|\n|   5|          0.361|     0.260|     0.463|\n|   6|          0.390|     0.289|     0.492|\n|   7|          0.420|     0.318|     0.521|\n\n\n:::\n:::\n\n\n### How to Use This Table\n\n1. **During training**: Monitor bar velocity in real-time\n2. **Stop the set** when velocity drops to your target RIR threshold\n3. **Example**: To leave 2 reps in reserve, stop when velocity reaches ~0.27 m/s\n\n### Visualization\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvt <- results$velocity_table$table\n\nif (\"load_percentage\" %in% names(vt)) {\n  ggplot(vt, aes(x = rir, y = velocity, color = load_percentage)) +\n    geom_line(linewidth = 1.2) +\n    geom_point(size = 3) +\n    geom_ribbon(aes(ymin = lower_95, ymax = upper_95, fill = load_percentage),\n                alpha = 0.2, color = NA) +\n    scale_color_manual(values = c(\"80%\" = \"#E69F00\", \"90%\" = \"#009E73\")) +\n    scale_fill_manual(values = c(\"80%\" = \"#E69F00\", \"90%\" = \"#009E73\")) +\n    labs(\n      x = \"Repetitions in Reserve (RIR)\",\n      y = \"Mean Velocity (m/s)\",\n      color = \"Load\",\n      fill = \"Load\"\n    ) +\n    theme_minimal() +\n    theme(legend.position = \"bottom\")\n} else {\n  ggplot(vt, aes(x = rir, y = velocity)) +\n    geom_line(linewidth = 1.2, color = \"#2E86AB\") +\n    geom_point(size = 3, color = \"#2E86AB\") +\n    geom_ribbon(aes(ymin = lower_95, ymax = upper_95),\n                alpha = 0.2, fill = \"#2E86AB\") +\n    labs(\n      x = \"Repetitions in Reserve (RIR)\",\n      y = \"Mean Velocity (m/s)\",\n      title = \"Global Velocity Stop Table for Deadlift\"\n    ) +\n    theme_minimal()\n}\n```\n\n::: {.cell-output-display}\n![Velocity Stop Thresholds by RIR](05_deadlift_lmm_analysis_files/figure-html/fig-velocity-table-1.png){#fig-velocity-table width=960}\n:::\n:::\n\n\n## General vs Individual Tables\n\nShould athletes use the **general table** or create their own **individual calibration**?\n\n\n::: {#tbl-individual-comparison .cell tbl-cap='General vs Individual Table Accuracy'}\n\n```{.r .cell-code}\nic <- results$individual_comparison\n\ncomparison_df <- data.frame(\n  Approach = c(\"General (Population)\", \"Individual (Calibrated)\"),\n  MAE = c(round(ic$global_mae * 1000, 2), round(ic$individual_mae * 1000, 2)),\n  RMSE = c(round(ic$global_rmse * 1000, 2), round(ic$individual_rmse * 1000, 2))\n)\n\nkable(comparison_df,\n      col.names = c(\"Approach\", \"MAE (mm/s)\", \"RMSE (mm/s)\"))\n```\n\n::: {.cell-output-display}\n\n\n|Approach                | MAE (mm/s)| RMSE (mm/s)|\n|:-----------------------|----------:|-----------:|\n|General (Population)    |      59.86|       79.17|\n|Individual (Calibrated) |      39.54|       51.75|\n\n\n:::\n:::\n\n\n**Improvement from individualization**: 34%\n\n**Recommendation**: Individual calibration recommended (>10% improvement)\n\n## Conformal Prediction Intervals\n\nTraditional prediction intervals assume normality. **Conformal prediction** provides **distribution-free** intervals with guaranteed coverage.\n\n### Method\n\n1. Split data: Day 1 (calibration), Day 2 (test)\n2. Calculate nonconformity scores (absolute residuals) on calibration set\n3. Find the 95th percentile of scores\n4. Use this to construct intervals on new data\n\n### Results\n\n\n::: {#tbl-conformal .cell tbl-cap='Conformal vs Parametric Prediction Intervals'}\n\n```{.r .cell-code}\nconf <- results$conformal\n\ncomparison_df <- data.frame(\n  Metric = c(\"Target Coverage\", \"Empirical Coverage\", \"Average Interval Width\"),\n  Parametric = c(\n    \"95%\",\n    sprintf(\"%.1f%%\", conf$comparison$parametric_coverage * 100),\n    sprintf(\"%.4f m/s\", conf$comparison$parametric_width)\n  ),\n  Conformal = c(\n    \"95%\",\n    sprintf(\"%.1f%%\", conf$comparison$conformal_coverage * 100),\n    sprintf(\"%.4f m/s\", conf$comparison$conformal_width)\n  )\n)\n\nkable(comparison_df, col.names = c(\"Metric\", \"Parametric\", \"Conformal\"))\n```\n\n::: {.cell-output-display}\n\n\n|Metric                 |Parametric |Conformal  |\n|:----------------------|:----------|:----------|\n|Target Coverage        |95%        |95%        |\n|Empirical Coverage     |83.4%      |95.6%      |\n|Average Interval Width |0.2114 m/s |0.2094 m/s |\n\n\n:::\n:::\n\n\n**Key Insight**:\n\n- Parametric coverage: 83.4% (deviation from 95%: 11.6%)\n- Conformal coverage: 95.6% (deviation from 95%: 0.6%)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (abs(results$conformal$comparison$conformal_coverage - 0.95) <\n    abs(results$conformal$comparison$parametric_coverage - 0.95)) {\n  cat(\"Conformal intervals achieve coverage closer to the 95% target.\\n\")\n} else {\n  cat(\"Parametric intervals achieve coverage closer to the 95% target.\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConformal intervals achieve coverage closer to the 95% target.\n```\n\n\n:::\n:::\n\n\n## Practical Implications\n\n### For Coaches and Athletes\n\n1. **Use velocity monitoring** during deadlift sets\n2. **Reference the velocity table** to estimate RIR in real-time\n3. **Consider individual calibration** for serious athletes (if improvement >10%)\n4. **Account for uncertainty**: Velocity estimates have ~209.4 mm/s margin of error\n\n### For Researchers\n\n1. **LMM is appropriate** for this nested data structure\n2. **Model assumptions are questionable - interpret with caution**\n3. **Conformal prediction** provides more reliable coverage guarantees\n\n## Limitations\n\n1. **Sample size**: 19 participants (adequate for LMM but limits generalizability)\n2. **Load range**: Only 80% and 90% tested\n3. **Exercise specificity**: Results apply to conventional deadlift only\n4. **Equipment**: Specific velocity measurement device used\n\n## Conclusions\n\n1. **A single global velocity table is sufficient** - load percentage does not significantly affect the velocity-RIR relationship\n\n2. **Individual calibration improves accuracy** by 34%\n\n3. **Conformal prediction** provides more reliable interval coverage than parametric methods\n\n4. **Velocity-based training** can effectively prescribe training intensity for deadlifts using the provided stop tables\n\n## Technical Notes\n\nThis analysis used:\n- **R6 classes** following SOLID principles\n- **lme4** for Linear Mixed Effects Models\n- **Split conformal prediction** for distribution-free intervals\n- **BIC-based Bayes Factor approximation** for model comparison\n\n## References\n\nThis methodology follows:\n\nNakagawa, S., & Schielzeth, H. (2013). A general and simple method for obtaining R² from generalized linear mixed-effects models. *Methods in Ecology and Evolution*, 4(2), 133-142.\n\nLei, J., G'Sell, M., Rinaldo, A., Tibshirani, R. J., & Wasserman, L. (2018). Distribution-Free Predictive Inference for Regression. *Journal of the American Statistical Association*, 113(523), 1094-1111.\n\nJukic, I., Prnjak, K., Helms, E. R., & McGuigan, M. R. (2024). Modeling the repetitions-in-reserve-velocity relationship. *Experimental Physiology*, 109(2), 193-206.\n",
    "supporting": [
      "05_deadlift_lmm_analysis_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}