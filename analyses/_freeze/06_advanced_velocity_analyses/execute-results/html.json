{
  "hash": "0bfaec0dbef93afcbed520c4055b198a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Study 6: Advanced Velocity-RIR Analyses\"\nsubtitle: \"Novel Analyses for Velocity-Based Training Prescription\"\nauthor:\n  - name: \"João Costa\"\n    affiliation: \"Sport Science Research\"\n  - name: \"Filipe Braga\"\n    affiliation: \"MSc Thesis Research\"\ndate: today\nformat:\n  html:\n    toc: true\n    toc-depth: 3\n    code-fold: true\n    code-summary: \"Show code\"\n    theme: cosmo\n    fig-width: 10\n    fig-height: 6\nexecute:\n  warning: false\n  message: false\n---\n\n\n\n\n## Executive Summary\n\nThis study presents five novel analyses (H2-H6) that extend our understanding of the deadlift velocity-RIR relationship, addressing key gaps in the velocity-based training literature that have practical implications for coaches and athletes.\n\n### Background and Motivation\n\nStudies 4 and 5 established the fundamental velocity-RIR relationship for deadlifts and provided practical velocity tables. However, several questions remain unanswered:\n\n1. **How variable is the failure velocity across individuals?** If everyone fails at the same velocity, a universal threshold works. If not, individual calibration is essential.\n\n2. **How stable are individual velocity profiles across days?** This determines how often athletes need to recalibrate their velocity zones.\n\n3. **Is the velocity-RIR relationship linear or curved?** This affects the mathematical model we should use.\n\n4. **Does velocity loss accelerate within a set?** This has implications for when to stop a set to preserve rep quality.\n\n5. **Can we predict set capacity from the first rep?** This would enable real-time autoregulation without counting reps.\n\nThis study addresses each of these questions with dedicated analyses.\n\n### Key Findings\n\n| Analysis | Result | Practical Implication |\n|----------|--------|----------------------|\n| **H2: MVT Variability** | CV = 30.8% | Individual calibration essential |\n| **H3: Day Reliability** | Slope ICC = 0.72 | Periodic recalibration needed |\n| **H4: Model Comparison** | 26.3% prefer quadratic | Linear model adequate |\n| **H5: Velocity Decay** | Accelerates (p = 0.035) | Non-linear considerations |\n| **H6: Failure Prediction** | MAE = 1.29 reps | First rep velocity useful |\n\n## Experimental Setup\n\n### Study Design\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nParticipants: 19 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTotal observations: 406 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTotal sets: 74 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReps per set: 1 - 8 (mean: 5.5 )\n```\n\n\n:::\n:::\n\n\n**Protocol:**\n\n- **Participants**: 19 resistance-trained individuals (15 male, 4 female)\n- **Exercise**: Conventional deadlift\n- **Loads**: 80% and 90% of 1RM\n- **Testing days**: 2 separate days\n- **Protocol**: Each participant performed sets to muscular failure at both loads on both days\n- **Measurement**: Mean concentric velocity (MCV) for each repetition using linear position transducer\n\n**Data Structure:**\n\nEach observation represents a single repetition within a set to failure:\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nTable: Sample data structure (first 10 rows)\n\n|id        |day   |load_percentage |set_id                  | rep_number| rir| mean_velocity| reps_to_failure|\n|:---------|:-----|:---------------|:-----------------------|----------:|---:|-------------:|---------------:|\n|Sebastião |Day 1 |90%             |Sebastião_Day1_90pct_S1 |          1|   3|         0.333|               4|\n|Sebastião |Day 1 |90%             |Sebastião_Day1_90pct_S1 |          2|   2|         0.293|               4|\n|Sebastião |Day 1 |90%             |Sebastião_Day1_90pct_S1 |          3|   1|         0.235|               4|\n|Sebastião |Day 1 |90%             |Sebastião_Day1_90pct_S1 |          4|   0|         0.246|               4|\n|Sebastião |Day 1 |80%             |Sebastião_Day1_80pct_S2 |          1|   5|         0.398|               6|\n|Sebastião |Day 1 |80%             |Sebastião_Day1_80pct_S2 |          2|   4|         0.363|               6|\n|Sebastião |Day 1 |80%             |Sebastião_Day1_80pct_S2 |          3|   3|         0.386|               6|\n|Sebastião |Day 1 |80%             |Sebastião_Day1_80pct_S2 |          4|   2|         0.387|               6|\n|Sebastião |Day 1 |80%             |Sebastião_Day1_80pct_S2 |          5|   1|         0.325|               6|\n|Sebastião |Day 1 |80%             |Sebastião_Day1_80pct_S2 |          6|   0|         0.206|               6|\n\n\n:::\n:::\n\n\n## H2: Minimum Velocity Threshold (MVT) Variability\n\n### Research Question\n\n**How variable is the velocity at muscular failure (RIR=0) across individuals?**\n\n### Theoretical Background\n\nThe **Minimum Velocity Threshold (MVT)** represents the velocity at which an athlete can no longer complete a repetition---essentially, their \"failure velocity.\" This concept was introduced by González-Badillo & Sánchez-Medina (2010) for the bench press, where they observed relatively consistent MVT values across individuals (~0.17 m/s).\n\nIf MVT is consistent across individuals, it could serve as a **universal failure indicator**---coaches could prescribe a \"stop velocity\" that works for all athletes. However, if MVT varies substantially, **individual calibration becomes essential**.\n\n### Why This Matters for Deadlifts\n\nThe deadlift may show different MVT patterns than other exercises because:\n\n1. **No stretch-shortening cycle**: Failure occurs from a dead stop, potentially affecting the velocity profile\n2. **Grip as a limiter**: Some athletes may fail due to grip rather than posterior chain exhaustion\n3. **Binary failure pattern**: Unlike grinding through a squat, deadlifts either leave the floor or they don't\n\n### Methods\n\n1. Extracted all observations at RIR = 0 (failure reps)\n2. Calculated population-level MVT statistics (mean, SD, CV, IQR)\n3. Calculated individual MVT for each participant\n4. Tested for sex differences using Mann-Whitney U test (non-parametric due to small groups)\n5. Tested for load differences (80% vs 90%) using paired comparison\n\n### Results\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nPopulation MVT Statistics:\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Mean: 0.206 m/s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  SD: 0.063 m/s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  CV: 30.8 %\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  IQR: 0.082 m/s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Range: 0.119 - 0.402 m/s\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Extract failure data\nfailure_data <- data[data$rir == 0, ]\n\n# Density plot\nggplot(failure_data, aes(x = mean_velocity)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 20, fill = \"steelblue\", alpha = 0.7) +\n  geom_density(color = \"darkred\", linewidth = 1) +\n  geom_vline(xintercept = mvt_result$population_stats$mean,\n             linetype = \"dashed\", color = \"black\", linewidth = 1) +\n  annotate(\"text\", x = mvt_result$population_stats$mean + 0.02, y = 5,\n           label = paste(\"Mean =\", round(mvt_result$population_stats$mean, 3), \"m/s\"),\n           hjust = 0) +\n  labs(x = \"Velocity at Failure (m/s)\", y = \"Density\",\n       title = \"MVT Distribution Across All Failure Observations\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![Distribution of Minimum Velocity Threshold (MVT) at failure](06_advanced_velocity_analyses_files/figure-html/h2-plot-1.png){width=960}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Individual MVT plot\nind_mvt <- mvt_result$individual_stats\nind_mvt <- ind_mvt[order(ind_mvt$mean_mvt), ]\nind_mvt$id <- factor(ind_mvt$id, levels = ind_mvt$id)\n\nggplot(ind_mvt, aes(x = id, y = mean_mvt, color = sex)) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = mean_mvt - sd_mvt, ymax = mean_mvt + sd_mvt),\n                width = 0.3) +\n  geom_hline(yintercept = mvt_result$population_stats$mean,\n             linetype = \"dashed\", color = \"gray50\") +\n  coord_flip() +\n  labs(x = \"Participant\", y = \"MVT (m/s)\",\n       title = \"Individual MVT with Standard Deviation\",\n       color = \"Sex\") +\n  scale_color_manual(values = c(\"female\" = \"#E41A1C\", \"male\" = \"#377EB8\")) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![Individual MVT values showing between-participant variability](06_advanced_velocity_analyses_files/figure-html/h2-individual-1.png){width=960}\n:::\n:::\n\n\n**Load Comparison:**\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n80% 1RM MVT: 0.217 ± 0.066 m/s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n90% 1RM MVT: 0.196 ± 0.061 m/s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDifference: 0.021 m/s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\np-value: 0.148 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSignificant: FALSE \n```\n\n\n:::\n:::\n\n\n### Interpretation\n\nThe coefficient of variation (CV = 30.8%) indicates **high inter-individual variability** in MVT. This finding has important practical implications:\n\n1. **A single MVT value cannot be applied to all athletes** - using a population mean (0.21 m/s) would underestimate capacity for some and overshoot for others\n2. **Individual calibration is essential** - each athlete needs their own MVT determined through testing to failure\n3. **No significant load effect** - MVT appears similar at 80% and 90% 1RM, suggesting MVT is an individual characteristic independent of load\n\n## H3: Day-to-Day Reliability\n\n### Research Question\n\n**Are individual velocity-RIR relationships stable across testing days?**\n\n### Theoretical Background\n\nThe practical utility of VBT depends critically on the **reliability** of individual velocity profiles. Reliability refers to the consistency of measurements across repeated testing occasions. In the context of VBT:\n\n- **High reliability** means an athlete's velocity-RIR curve is stable---once calibrated, the velocity zones remain valid for an extended period\n- **Low reliability** means the curve shifts substantially between sessions, requiring frequent recalibration\n\nThe **Intraclass Correlation Coefficient (ICC)** is the standard metric for assessing reliability of continuous measures. We use ICC(2,1)---a two-way random effects model assuming both raters (days) and subjects are random samples from larger populations (Shrout & Fleiss, 1979).\n\n### Why This Matters\n\nIf velocity profiles are reliable day-to-day:\n\n- A **single calibration session is sufficient** to establish individual velocity zones\n- Athletes don't need frequent retesting\n- Coaches can trust that velocity thresholds remain valid\n\nIf velocity profiles are unreliable:\n\n- Athletes need **frequent recalibration** (perhaps weekly or monthly)\n- Session-to-session factors (fatigue, recovery, motivation) may affect velocity targets\n- VBT becomes less practical for day-to-day training prescription\n\n### Methods\n\n1. Fit individual linear models (velocity ~ RIR) for Day 1 and Day 2 separately\n2. Extract slopes (velocity loss per RIR) and intercepts (baseline velocity)\n3. Calculate MVT predictions for each day (predicted velocity at RIR = 0)\n4. Compute ICC(2,1) - two-way random effects model\n5. Calculate SEM (Standard Error of Measurement) and MDC95 (Minimal Detectable Change)\n\n**ICC Interpretation (Koo & Li, 2016):**\n\n| ICC | Interpretation |\n|-----|----------------|\n| < 0.50 | Poor |\n| 0.50-0.75 | Moderate |\n| 0.75-0.90 | Good |\n| > 0.90 | Excellent |\n\nThe **SEM** represents the typical measurement error, while **MDC95** is the minimum change needed to be 95% confident that a true change has occurred (rather than measurement error).\n\n### Results\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nSlope ICC (velocity loss per RIR):\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  ICC: 0.72 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  95% CI: 0.644 - 0.796 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Interpretation: Moderate \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMVT ICC (predicted failure velocity):\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  ICC: 0.498 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  95% CI: 0.379 - 0.617 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Interpretation: Poor \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  SEM: 0.024 m/s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  MDC95: 0.0666 m/s\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nday_params <- reliability$day_parameters\n\n# Slopes comparison\nggplot(day_params, aes(x = slope_day1, y = slope_day2)) +\n  geom_point(size = 3, alpha = 0.7) +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"gray50\") +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"steelblue\") +\n  labs(x = \"Slope Day 1 (m/s per RIR)\", y = \"Slope Day 2 (m/s per RIR)\",\n       title = \"Day-to-Day Reliability of Individual Slopes\",\n       subtitle = paste(\"ICC =\", round(reliability$slope_icc$icc, 2))) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![Day 1 vs Day 2 comparison of individual slopes](06_advanced_velocity_analyses_files/figure-html/h3-plot-1.png){width=960}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(day_params, aes(x = mvt_day1, y = mvt_day2)) +\n  geom_point(size = 3, alpha = 0.7) +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"gray50\") +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"steelblue\") +\n  labs(x = \"MVT Day 1 (m/s)\", y = \"MVT Day 2 (m/s)\",\n       title = \"Day-to-Day Reliability of Predicted MVT\",\n       subtitle = paste(\"ICC =\", round(reliability$mvt_icc$icc, 2))) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![Day 1 vs Day 2 comparison of predicted MVT](06_advanced_velocity_analyses_files/figure-html/h3-mvt-plot-1.png){width=960}\n:::\n:::\n\n\n### Interpretation\n\n- **Slope reliability is moderate** (ICC = 0.72), suggesting the rate of velocity decline per RIR is reasonably consistent\n- **MVT reliability is poor** (ICC = 0.5), indicating that predicted failure velocity varies substantially between days\n- **MDC95 = 0.067 m/s** - changes in MVT smaller than this may represent measurement error rather than true change\n\n**Practical recommendation:** Consider periodic recalibration (every 2-4 weeks) rather than relying on a single test session.\n\n## H4: Polynomial vs Linear Model Comparison\n\n### Research Question\n\n**Does a quadratic model fit the velocity-RIR relationship better than linear?**\n\n### Theoretical Background\n\nThe simplest model of the velocity-RIR relationship assumes **linear decay**---each additional rep costs the same amount of velocity. However, physiological fatigue often follows non-linear patterns:\n\n- **Metabolic fatigue** (e.g., lactate accumulation, ATP depletion) may compound near failure\n- **Neural fatigue** (motor unit dropout, decreased firing rates) may accelerate in later reps\n- **Technical breakdown** often becomes more pronounced as fatigue accumulates\n\nThese factors suggest the velocity-RIR relationship might be **curvilinear**, with velocity dropping more rapidly near failure (small RIR values) than earlier in the set.\n\n### Model Comparison Framework\n\nWe compare two models:\n\n- **Linear**: velocity = β₀ + β₁(RIR) + ε\n- **Quadratic**: velocity = β₀ + β₁(RIR) + β₂(RIR²) + ε\n\nThe quadratic model adds a curvature term. If β₂ < 0, velocity drops more rapidly near failure (accelerating decay). If β₂ ≈ 0, the relationship is approximately linear.\n\nWe use information criteria (AIC, BIC) rather than raw R² because they penalize model complexity---a quadratic model should only be preferred if the improvement justifies the added parameter.\n\n### Methods\n\n1. For each participant, fit:\n   - Linear: velocity ~ RIR\n   - Quadratic: velocity ~ RIR + RIR²\n2. Compare using adjusted R², AIC, and BIC\n3. Fit population-level LMM versions and conduct likelihood ratio test\n4. Count how many participants show significantly better fit with quadratic\n\n### Results\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nIndividual Model Comparison:\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Participants analyzed: 19 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Linear preferred: 14 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Quadratic preferred: 5 ( 26.3 %)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Avg R² improvement (quad - linear): 0.0164 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nind_results <- poly_result$individual_results\n\nggplot(ind_results, aes(x = reorder(id, delta_aic), y = delta_aic, fill = best_model)) +\n  geom_col() +\n  geom_hline(yintercept = -2, linetype = \"dashed\", color = \"red\") +\n  geom_hline(yintercept = 2, linetype = \"dashed\", color = \"red\") +\n  annotate(\"text\", x = 1, y = -3, label = \"Quadratic better\", hjust = 0, color = \"gray40\") +\n  annotate(\"text\", x = 1, y = 3, label = \"Linear better\", hjust = 0, color = \"gray40\") +\n  coord_flip() +\n  labs(x = \"Participant\", y = \"ΔAIC (Quadratic - Linear)\",\n       title = \"Model Comparison by Participant\",\n       subtitle = \"Negative values favor quadratic model\",\n       fill = \"Best Model\") +\n  scale_fill_manual(values = c(\"linear\" = \"steelblue\", \"quadratic\" = \"coral\")) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![AIC comparison between linear and quadratic models by participant](06_advanced_velocity_analyses_files/figure-html/h4-plot-1.png){width=960}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(ind_results, aes(x = r2_adj_linear, y = r2_adj_quad)) +\n  geom_point(aes(color = best_model), size = 3) +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\") +\n  labs(x = \"Adjusted R² (Linear)\", y = \"Adjusted R² (Quadratic)\",\n       title = \"Model Fit Comparison\",\n       color = \"Best Model\") +\n  scale_color_manual(values = c(\"linear\" = \"steelblue\", \"quadratic\" = \"coral\")) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![R² comparison between linear and quadratic models](06_advanced_velocity_analyses_files/figure-html/h4-r2-1.png){width=960}\n:::\n:::\n\n\n### Interpretation\n\nOnly 26.3% of participants show a meaningfully better fit with the quadratic model. This suggests:\n\n1. **Linear model is generally adequate** for describing the velocity-RIR relationship\n2. The additional complexity of a quadratic term is not justified for most individuals\n3. Practitioners can confidently use **linear velocity zones** for training prescription\n\n**Note:** While a minority of individuals may benefit from quadratic modeling, the linear approximation provides sufficient accuracy for practical applications.\n\n## H5: Velocity Decay Rate Within Sets\n\n### Research Question\n\n**How does velocity loss per rep change as a set progresses?**\n\n### Theoretical Background\n\nWhile H4 examined the overall shape of the velocity-RIR curve, this analysis focuses on the **within-set dynamics**---specifically, whether velocity loss per rep is constant or accelerates as the set progresses.\n\nTwo competing hypotheses exist:\n\n1. **Constant decay hypothesis**: Each rep costs approximately the same velocity, regardless of position in the set. This would suggest fatigue accumulates linearly.\n\n2. **Accelerating decay hypothesis**: Later reps cost more velocity than earlier reps. This would suggest fatigue compounds---possibly due to metabolite accumulation, motor unit fatigue, or technique degradation.\n\nThe practical implications are significant:\n\n- **Constant decay**: Simple rep-counting or fixed velocity loss thresholds work well\n- **Accelerating decay**: Athletes should stop sets earlier than velocity loss alone might suggest, as the final reps represent disproportionate fatigue\n\n### Why This Matters for Training Quality\n\nIf velocity decay accelerates near failure:\n\n- **Rep quality deteriorates non-linearly**: The last 1-2 reps may be substantially lower quality than earlier reps\n- **Technical breakdown risk increases**: Form often degrades as fatigue compounds\n- **Recovery cost may be disproportionate**: The final grinding reps may cost more in recovery than they contribute to adaptation\n\nUnderstanding decay patterns helps coaches make informed decisions about set termination criteria.\n\n### Methods\n\n1. Calculate rep-to-rep velocity change (Δv = v_n - v_{n-1})\n2. Model decay rate vs rep number: Δv ~ rep_number\n3. Test if decay accelerates (negative slope = accelerating fatigue)\n4. Compare early reps (1-3) vs late reps (4+) decay rates\n\n### Results\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nVelocity Decay Summary:\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Average decay per rep: -0.0283 m/s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Early reps (1-3): -0.0206 m/s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Late reps (4+): -0.0338 m/s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Acceleration: -0.0132 m/s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAcceleration Test:\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Slope: -0.00318 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  p-value: 0.03495 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Interpretation: Decay accelerates toward failure \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create spaghetti plot of velocity trajectories\nggplot(data, aes(x = rep_number, y = mean_velocity, group = set_id)) +\n  geom_line(alpha = 0.3, color = \"steelblue\") +\n  stat_summary(aes(group = 1), fun = mean, geom = \"line\",\n               color = \"darkred\", linewidth = 1.5) +\n  stat_summary(aes(group = 1), fun = mean, geom = \"point\",\n               color = \"darkred\", size = 3) +\n  labs(x = \"Rep Number\", y = \"Mean Velocity (m/s)\",\n       title = \"Velocity Trajectories Across Sets\",\n       subtitle = \"Individual sets (blue) with population mean (red)\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![Velocity trajectories for individual sets](06_advanced_velocity_analyses_files/figure-html/h5-trajectory-1.png){width=960}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Decay by rep number\ndecay_data <- decay$set_trajectories\n\nggplot(decay_data, aes(x = factor(rep_number), y = delta_v)) +\n  geom_boxplot(fill = \"steelblue\", alpha = 0.7) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"gray50\") +\n  labs(x = \"Rep Number\", y = \"Velocity Change from Previous Rep (m/s)\",\n       title = \"Rep-to-Rep Velocity Change\",\n       subtitle = \"Negative values indicate velocity loss\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![Rep-to-rep velocity change by rep number](06_advanced_velocity_analyses_files/figure-html/h5-decay-1.png){width=960}\n:::\n:::\n\n\n### Interpretation\n\n**Velocity decay accelerates as the set progresses** (p = 0.035):\n\n- Early reps (1-3): Average decay = 20.6 mm/s per rep\n- Late reps (4+): Average decay = 33.8 mm/s per rep\n\nThis 13.2 mm/s acceleration in decay rate suggests:\n\n1. **Fatigue compounds near failure** - the last few reps cost more velocity than earlier reps\n2. **Velocity thresholds are conservative early** - athletes have more \"buffer\" in early reps\n3. **Quality deteriorates rapidly near failure** - this supports stopping 1-2 reps before failure for technique preservation\n\n## H6: Early Rep Velocity for Failure Prediction\n\n### Research Question\n\n**Can the first 1-3 rep velocities predict when failure will occur?**\n\n### Theoretical Background\n\nThe concept of using early-rep velocity to predict set capacity builds on the **load-velocity relationship** established in the VBT literature (González-Badillo & Sánchez-Medina, 2010). The fundamental insight is that first-rep velocity reflects:\n\n1. **Relative intensity**: Faster first reps indicate lighter relative loads → more reps available\n2. **Daily readiness**: Day-to-day fluctuations in strength affect first-rep velocity\n3. **Fatigue state**: Accumulated fatigue reduces first-rep velocity\n\nBy combining first-rep velocity with the known velocity-RIR relationship, we can theoretically predict total set capacity before completing the set.\n\n### Why This Matters for Practical Training\n\nThis analysis addresses the most practically valuable question for coaches and athletes:\n\n1. **Real-time autoregulation**: Instead of counting reps or guessing RIR, athletes can use first-rep velocity to know approximately how many quality reps are available.\n\n2. **Pre-set planning**: Before starting, athletes can perform a \"velocity check\" with the first rep to decide on set termination strategy.\n\n3. **Daily autoregulation**: On days when first-rep velocity is unexpectedly low, athletes can adjust expectations and avoid overreaching.\n\n### Leave-One-Set-Out Cross-Validation\n\nWe use leave-one-set-out cross-validation (LOOCV) to estimate prediction accuracy. For each set:\n\n1. Fit the prediction model on all other sets\n2. Predict the excluded set's total reps from its first-rep velocity\n3. Calculate prediction error\n\nThis approach provides an honest estimate of how well the model generalizes to new data.\n\n### Methods\n\n1. For each set, extract: v1 (first rep velocity), v2, v3, and total reps\n2. Build prediction models:\n   - Model 1: reps ~ v1\n   - Model 2: reps ~ v1 + v2\n   - Model 3: reps ~ v1 + v2 + v3\n   - Model 4: reps ~ v1 + load\n3. Evaluate with leave-one-set-out cross-validation\n4. Create practical lookup table\n\n### Results\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nLeave-One-Set-Out Cross-Validation:\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Sets analyzed: 66 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  MAE: 1.29 reps\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  RMSE: 1.53 reps\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  R²: 0.065 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Within ±1 rep: 42.4 %\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Within ±2 reps: 75.8 %\n```\n\n\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nTable: Practical Lookup Table: First Rep Velocity → Predicted Reps\n\n| First Rep Velocity (m/s)| Predicted Reps| Lower 95%| Upper 95%|\n|------------------------:|--------------:|---------:|---------:|\n|                      0.1|            4.9|       1.8|       8.0|\n|                      0.2|            5.2|       2.1|       8.3|\n|                      0.2|            5.4|       2.4|       8.5|\n|                      0.3|            5.7|       2.6|       8.7|\n|                      0.3|            6.0|       2.9|       9.0|\n|                      0.4|            6.2|       3.2|       9.3|\n|                      0.5|            6.5|       3.4|       9.6|\n|                      0.5|            6.8|       3.7|       9.9|\n|                      0.6|            7.0|       3.9|      10.2|\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Prepare set-level data\nset_data <- do.call(rbind, lapply(unique(data$set_id), function(sid) {\n  s <- data[data$set_id == sid, ]\n  s <- s[order(s$rep_number), ]\n  if (nrow(s) < 1) return(NULL)\n  data.frame(\n    set_id = sid,\n    v1 = s$mean_velocity[1],\n    reps_to_failure = s$reps_to_failure[1],\n    load_percentage = s$load_percentage[1]\n  )\n}))\n\nggplot(set_data, aes(x = v1, y = reps_to_failure, color = load_percentage)) +\n  geom_point(size = 3, alpha = 0.7) +\n  geom_smooth(method = \"lm\", se = TRUE, aes(group = 1), color = \"black\") +\n  labs(x = \"First Rep Velocity (m/s)\", y = \"Total Reps to Failure\",\n       title = \"Relationship Between First Rep Velocity and Set Capacity\",\n       color = \"Load\") +\n  scale_color_manual(values = c(\"80%\" = \"#E41A1C\", \"90%\" = \"#377EB8\")) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![First rep velocity vs total reps completed](06_advanced_velocity_analyses_files/figure-html/h6-plot-1.png){width=960}\n:::\n:::\n\n\n### Interpretation\n\nThe first rep velocity provides a **reasonable prediction of set capacity**:\n\n- **MAE = 1.29 reps** means predictions are typically within ~1 rep of actual\n- **75.8% accuracy within ±2 reps** is sufficient for practical autoregulation\n- **Each +0.1 m/s in first rep velocity → ~0.5 additional reps expected**\n\n**Practical Application:**\nUse the lookup table to estimate available reps from your first rep velocity. For example:\n- First rep at 0.30 m/s → Expect ~6 reps (95% PI: 3-9)\n- First rep at 0.45 m/s → Expect ~7 reps (95% PI: 3-10)\n\n## Practical Implications\n\n### Summary of Recommendations\n\n| Finding | Practical Recommendation |\n|---------|-------------------------|\n| High MVT variability (CV = 31%) | Calibrate MVT individually for each athlete |\n| Moderate slope reliability (ICC = 0.72) | Recalibrate velocity zones every 2-4 weeks |\n| Linear model adequate | Use simple linear velocity zones |\n| Decay accelerates near failure | Stop 1-2 reps from failure for quality |\n| First rep predicts set capacity | Use first rep velocity for autoregulation |\n\n### Implementation Steps\n\n1. **Initial Calibration**: Test each athlete to failure at submaximal loads (75-85% 1RM) to establish individual MVT\n2. **Set Up Zones**: Create linear velocity zones from MVT to maximum velocity\n3. **Monitor First Rep**: Use first rep velocity to estimate available reps\n4. **Stop Before Failure**: Given acceleration of velocity loss, target stopping 1-2 reps before predicted failure\n5. **Recalibrate Periodically**: Update velocity zones every 2-4 weeks or after significant training blocks\n\n## Limitations\n\nThis study has several limitations that should be considered:\n\n1. **Sample size**: With 19 participants, statistical power is limited, particularly for subgroup analyses (e.g., sex differences). Effect sizes may be imprecise.\n\n2. **Exercise specificity**: All findings apply specifically to the conventional deadlift. Sumo deadlifts, trap bar deadlifts, and other exercises may show different patterns.\n\n3. **Load range**: Only 80% and 90% 1RM were tested. Lighter loads commonly used in hypertrophy training (60-75% 1RM) may exhibit different velocity dynamics.\n\n4. **Short-term reliability only**: With only 2 testing days, we cannot assess longer-term reliability (week-to-week, month-to-month) or the effects of training adaptations on velocity profiles.\n\n5. **Population specificity**: All participants were Portuguese resistance-trained individuals. Results may not generalize to different populations, training backgrounds, or skill levels (e.g., novice lifters).\n\n6. **Prediction intervals**: The failure prediction lookup table is based on this sample only. Individual athletes may show systematic deviations from these population averages.\n\n## Conclusions\n\nThis study provides novel insights into the velocity-RIR relationship for the conventional deadlift:\n\n1. **MVT is highly variable** (CV ~31%), confirming that individual calibration is essential for accurate velocity-based prescriptions.\n\n2. **Day-to-day reliability is moderate** for velocity-RIR slopes, suggesting periodic recalibration (every 2-4 weeks) is advisable.\n\n3. **Linear models are generally adequate**, with only a minority of individuals showing meaningfully better fit with quadratic models.\n\n4. **Velocity decay accelerates near failure**, supporting the practice of stopping sets 1-2 reps before failure to preserve rep quality.\n\n5. **First-rep velocity predicts set capacity** with reasonable accuracy (~1-2 rep error), enabling practical real-time autoregulation.\n\nThese findings extend the evidence base for velocity-based training to the deadlift, while highlighting the importance of individualization and the limitations of universal velocity thresholds.\n\n## References\n\n- González-Badillo, J. J., & Sánchez-Medina, L. (2010). Movement velocity as a measure of loading intensity in resistance training. *International Journal of Sports Medicine*, 31(5), 347-352.\n\n- Jukic, I., Prnjak, K., Helms, E. R., & McGuigan, M. R. (2024). Modeling the repetitions-in-reserve-velocity relationship: A valid method for resistance training monitoring and prescription, and fatigue management. *Experimental Physiology*, 109(2), 193-206.\n\n- Koo, T. K., & Li, M. Y. (2016). A guideline of selecting and reporting intraclass correlation coefficients for reliability research. *Journal of Chiropractic Medicine*, 15(2), 155-163.\n\n- Shrout, P. E., & Fleiss, J. L. (1979). Intraclass correlations: Uses in assessing rater reliability. *Psychological Bulletin*, 86(2), 420-428.\n\n- Zourdos, M. C., Klemp, A., Dolan, C., Quiles, J. M., Schau, K. A., Jo, E., ... & Blanco, R. (2016). Novel resistance training–specific rating of perceived exertion scale measuring repetitions in reserve. *Journal of Strength and Conditioning Research*, 30(1), 267-275.\n\n---\n\n*Study 6 of the Deadlift RIR-Velocity Research Project*\n\n*Part of Filipe Braga's MSc thesis research*\n\n*Analysis performed using R R version 4.3.3 (2024-02-29) with custom R6 classes following SOLID principles*\n",
    "supporting": [
      "06_advanced_velocity_analyses_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}