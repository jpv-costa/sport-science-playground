{
  "hash": "ea83380d1be512f2c3cadf3d9077ac4e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Velocity-Based Training for the Conventional Deadlift\"\nsubtitle: \"An Investigation of the RIR-Velocity Relationship\"\nauthor:\n  - name: \"João Costa\"\n    affiliation: \"Sport Science Research\"\n  - name: \"Filipe Braga\"\n    affiliation: \"MSc Thesis Research\"\ndate: today\nformat:\n  html:\n    toc: true\n    toc-depth: 3\n    code-fold: true\n    code-summary: \"Show code\"\n  pdf:\n    toc: true\n    toc-depth: 3\n    number-sections: true\n    colorlinks: true\n    papersize: a4\n    geometry:\n      - margin=2.5cm\n    include-in-header:\n      text: |\n        \\usepackage{booktabs}\n        \\usepackage{longtable}\nbibliography: references.bib\n---\n\n\n\n\n\n## Executive Summary\n\nThis research investigates whether velocity-based training (VBT) principles, well-established for exercises like the squat and bench press, can be successfully applied to the **conventional deadlift**---an exercise with unique biomechanical characteristics.\n\n### Key Findings\n\n| Question | Finding | Practical Implication |\n|----------|---------|----------------------|\n| **Does VBT work for deadlifts?** | Yes, but with more variability | Use VBT as one tool, not the only tool |\n| **Individual vs general models?** | Individual ~2x more accurate | Calibrate individually for serious athletes |\n| **Does load matter?** | No significant effect | One velocity table works across loads |\n| **MVT variability?** | CV = 30.8% | Individual calibration essential |\n| **Day-to-day reliability?** | Moderate (ICC ~0.5-0.7) | Recalibrate every 2-4 weeks |\n| **First-rep prediction?** | MAE = 1.29 reps | Useful for real-time autoregulation |\n\n---\n\n## 1. Introduction\n\n### 1.1 Background\n\nVelocity-Based Training (VBT) has emerged as an objective method for monitoring and prescribing resistance training intensity. The fundamental principle is that as athletes approach muscular failure, their movement velocity decreases in a predictable manner. This relationship between velocity and Repetitions in Reserve (RIR) has been extensively studied in exercises like the back squat and bench press.\n\nThe theoretical foundation for VBT rests on the **force-velocity relationship**: as fatigue accumulates, the maximum force a muscle can produce decreases, resulting in slower movement at any given load. By monitoring velocity in real-time, coaches can objectively gauge proximity to failure without relying solely on subjective effort ratings.\n\n### 1.2 The Deadlift Challenge\n\nThe **conventional deadlift** presents unique biomechanical characteristics that may affect the velocity-RIR relationship:\n\n1. **Concentric-only initiation**: Unlike the squat, the deadlift begins from a dead stop without an eccentric-concentric stretch-shortening cycle, eliminating the elastic energy contribution\n\n2. **Grip as a limiting factor**: The grip can become a limiting factor independent of the target musculature (posterior chain), potentially causing failure before true muscular exhaustion\n\n3. **Binary failure pattern**: Deadlifts tend to fail more abruptly---either the bar leaves the floor or it doesn't---compared to the gradual \"grinding\" often seen in squats\n\n4. **Longer lever arms**: The horizontal distance between the load and hip joint creates substantial moment arms that change throughout the lift\n\n### 1.3 Research Questions\n\nThis thesis research addresses six key questions:\n\n1. Does a meaningful velocity-RIR relationship exist for deadlifts?\n2. Do individual models outperform general equations?\n3. Does load percentage affect the velocity-RIR relationship?\n4. How variable is the minimum velocity threshold (MVT) across individuals?\n5. How reliable are individual velocity profiles across testing days?\n6. Can first-rep velocity predict set capacity?\n\n---\n\n## 2. Methods\n\n### 2.1 Participants\n\n\n\n::: {#tbl-participants .cell tbl-cap='Participant Characteristics'}\n\n```{.r .cell-code}\nsummary_df <- data.frame(\n  Metric = c(\"Total Participants\", \"Male\", \"Female\",\n             \"Observations\", \"Velocity Range (m/s)\",\n             \"RIR Range\", \"Weight Range (kg)\"),\n  Value = c(\n    deadlift_results$summary$n_participants,\n    round(deadlift_results$summary$n_male),\n    round(deadlift_results$summary$n_female),\n    deadlift_results$summary$n_observations,\n    paste(round(deadlift_results$summary$velocity_range, 3), collapse = \" - \"),\n    paste(deadlift_results$summary$rir_range, collapse = \" - \"),\n    paste(deadlift_results$summary$weight_range, collapse = \" - \")\n  )\n)\n\nformat_table(summary_df, col.names = c(\"\", \"\"))\n```\n\n::: {.cell-output-display}\n\n\n|                     |              |\n|:--------------------|:-------------|\n|Total Participants   |19            |\n|Male                 |15            |\n|Female               |4             |\n|Observations         |406           |\n|Velocity Range (m/s) |0.119 - 0.675 |\n|RIR Range            |0 - 7         |\n|Weight Range (kg)    |85 - 210      |\n\n\n:::\n:::\n\n\n\n### 2.2 Protocol\n\nParticipants performed the conventional deadlift under standardized conditions:\n\n- **Exercise**: Conventional deadlift with standard Olympic barbell\n- **Loads**: 80% and 90% of 1RM (determined via prior 1RM testing)\n- **Testing Days**: 2 separate days (minimum 48-72 hours apart) for cross-validation\n- **Sets per condition**: Each load tested on each day (4 total conditions per participant)\n- **Rest periods**: 3-5 minutes between sets\n- **Failure criterion**: Inability to complete a full repetition or voluntary termination\n\n### 2.3 Velocity Measurement\n\nMean concentric velocity (MCV) was measured using a linear position transducer attached to the barbell. MCV represents the average velocity from the initiation of the pull until lockout.\n\n### 2.4 RIR Assignment\n\nRIR was assigned **prospectively** based on set completion:\n\n- Final repetition completed = RIR 0 (failure)\n- Penultimate repetition = RIR 1\n- And so forth...\n\nThis differs from subjective RIR estimates, providing an objective measure of proximity to failure.\n\n### 2.5 Statistical Analysis\n\nThe analysis employed multiple complementary approaches:\n\n**Individual vs General Models:**\n\n- General models: Population-level polynomial regression (velocity ~ RIR + RIR²)\n- Individual models: Participant-specific polynomial regressions\n- Cross-validation: Day 1 models tested on Day 2 data\n\n**Linear Mixed Effects Models (LMM):**\n\nLMMs account for the nested data structure (repetitions within participants) by including:\n\n- **Fixed effects**: Population-average relationships\n- **Random effects**: Individual deviations (random intercepts and slopes)\n\n**Advanced Analyses:**\n\n- MVT variability assessment (CV, IQR)\n- Day-to-day reliability (ICC)\n- Polynomial vs linear model comparison (AIC, BIC)\n- Velocity decay analysis\n- Failure prediction from early rep velocities (LOOCV)\n\n---\n\n## 3. Results\n\n### 3.1 The Velocity-RIR Relationship\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data, aes(x = mean_velocity, y = rir, color = load_percentage)) +\n  geom_point(alpha = 0.4, size = 2) +\n  geom_smooth(method = \"lm\", formula = y ~ poly(x, 2), se = FALSE, linewidth = 1.2) +\n  facet_wrap(~load_percentage, labeller = labeller(load_percentage = c(\n    `80%` = \"80% 1RM\",\n    `90%` = \"90% 1RM\"\n  ))) +\n  scale_color_load() +\n  labs(\n    x = \"Mean Velocity (m/s)\",\n    y = \"Repetitions in Reserve\"\n  ) +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![Velocity-RIR relationship for conventional deadlift](deadlift_study_files/figure-pdf/fig-scatter-1.pdf){#fig-scatter fig-pos='H' width=100%}\n:::\n:::\n\n\n\nA clear negative relationship exists: higher RIR (more reps remaining) is associated with faster velocities. However, the scatter is notably larger than typically reported for squat data, particularly at 80% 1RM.\n\n### 3.2 General vs Individual Models\n\n\n\n::: {#tbl-models .cell tbl-cap='Model Fit Comparison'}\n\n```{.r .cell-code}\ncomparison_df <- data.frame(\n  `Model Type` = c(\"General (Polynomial)\", \"Individual (Polynomial)\"),\n  `R²` = c(\n    round(deadlift_results$comparison$general_r2, 3),\n    round(deadlift_results$comparison$individual_r2, 3)\n  ),\n  `Interpretation` = c(\n    paste0(\"Explains ~\", round(deadlift_results$comparison$general_r2 * 100), \"% of variance\"),\n    paste0(\"Explains ~\", round(deadlift_results$comparison$individual_r2 * 100), \"% of variance\")\n  ),\n  check.names = FALSE\n)\n\nformat_table(comparison_df)\n```\n\n::: {.cell-output-display}\n\n\n|                        |      |                          |\n|:-----------------------|-----:|:-------------------------|\n|General (Polynomial)    | 0.362|Explains ~36% of variance |\n|Individual (Polynomial) | 0.707|Explains ~71% of variance |\n\n\n:::\n:::\n\n\n\n**Key Finding**: Individual models explain **2x more variance** than general models, consistent with squat research. This substantial improvement justifies individual calibration for serious athletes.\n\n### 3.3 Exercise Comparison: Deadlift vs Squat\n\n\n\n::: {#tbl-exercise-comparison .cell tbl-cap='Deadlift vs Squat RIR-Velocity Relationship'}\n\n```{.r .cell-code}\nexercise_comparison <- data.frame(\n  Metric = c(\"Participants\", \"Load Types\", \"General R²\", \"Individual R²\", \"Improvement Factor\"),\n  Squat = c(\n    \"46\", \"70%, 80%, 90%\",\n    round(squat_results$comparison$general_r2, 2),\n    round(squat_results$comparison$individual_r2, 2),\n    paste0(round(squat_results$comparison$improvement_factor, 2), \"x\")\n  ),\n  Deadlift = c(\n    as.character(deadlift_results$summary$n_participants),\n    \"80%, 90%\",\n    round(deadlift_results$comparison$general_r2, 2),\n    round(deadlift_results$comparison$individual_r2, 2),\n    paste0(round(deadlift_results$comparison$improvement_factor, 2), \"x\")\n  )\n)\n\nformat_table(exercise_comparison)\n```\n\n::: {.cell-output-display}\n\n\n|                   |              |         |\n|:------------------|:-------------|:--------|\n|Participants       |46            |19       |\n|Load Types         |70%, 80%, 90% |80%, 90% |\n|General R²         |0.5           |0.36     |\n|Individual R²      |0.88          |0.71     |\n|Improvement Factor |1.78x         |1.95x    |\n\n\n:::\n:::\n\n\n\nThe deadlift shows **lower R² values** than the squat, likely due to:\n\n1. **Binary failure pattern**: Less intermediate velocity signal\n2. **Grip fatigue**: Introduces noise uncorrelated with true RIR\n3. **Absence of stretch-shortening cycle**: Increased rep-to-rep variability\n4. **Technical breakdown**: May affect velocity differently than pure muscular fatigue\n\n### 3.4 Cross-Day Prediction Accuracy\n\nA critical test of any VBT model is its ability to predict performance on novel occasions. We tested Day 1 models on Day 2 data:\n\n\n\n::: {#tbl-prediction .cell tbl-cap='Cross-Day Prediction Accuracy'}\n\n```{.r .cell-code}\nif (!is.null(deadlift_results$general_prediction_accuracy)) {\n  accuracy <- deadlift_results$general_prediction_accuracy\n\n  prediction_df <- data.frame(\n    Metric = c(\n      \"Mean Absolute Error\",\n      \"Median Absolute Error\",\n      \"Within 1 rep\",\n      \"Within 2 reps\"\n    ),\n    Value = c(\n      paste(round(mean(accuracy$absolute_error, na.rm = TRUE), 2), \"reps\"),\n      paste(round(median(accuracy$absolute_error, na.rm = TRUE), 2), \"reps\"),\n      paste0(round(mean(accuracy$absolute_error <= 1, na.rm = TRUE) * 100, 1), \"%\"),\n      paste0(round(mean(accuracy$absolute_error <= 2, na.rm = TRUE) * 100, 1), \"%\")\n    )\n  )\n\n  format_table(prediction_df, col.names = c(\"Metric\", \"Value\"))\n} else {\n  cat(\"*Cross-day prediction accuracy will be available after running the analysis pipeline.*\\n\")\n}\n```\n\n::: {.cell-output-display}\n\n\n|Metric                |Value     |\n|:---------------------|:---------|\n|Mean Absolute Error   |1.39 reps |\n|Median Absolute Error |1.15 reps |\n|Within 1 rep          |46.8%     |\n|Within 2 reps         |72.2%     |\n\n\n:::\n:::\n\n\n\nThese prediction errors (~1.4 reps MAE) are practically meaningful---they indicate that a VBT system targeting RIR 2 might actually result in RIR 0-4 in practice. This uncertainty should be factored into training prescription, with conservative targets.\n\n### 3.5 Velocity Distribution by Load\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data, aes(x = factor(rir), y = mean_velocity, fill = load_percentage)) +\n  geom_boxplot(alpha = 0.5, outlier.shape = NA, width = 0.7) +\n  geom_point(\n    aes(color = load_percentage),\n    position = position_jitterdodge(jitter.width = 0.15, dodge.width = 0.7),\n    alpha = 0.6, size = 1.5\n  ) +\n  labs(\n    x = \"Repetitions in Reserve\",\n    y = \"Mean Velocity (m/s)\",\n    fill = \"Load\",\n    color = \"Load\"\n  ) +\n  scale_fill_load() +\n  scale_color_manual(values = c(\"80%\" = \"#CC7A00\", \"90%\" = \"#007A5E\")) +\n  theme(legend.position = \"bottom\") +\n  guides(fill = guide_legend(override.aes = list(alpha = 0.7)),\n         color = \"none\")\n```\n\n::: {.cell-output-display}\n![Velocity distribution by load and RIR](deadlift_study_files/figure-pdf/fig-velocity-load-1.pdf){#fig-velocity-load fig-pos='H' width=100%}\n:::\n:::\n\n\n\n**Observations:**\n\n- Higher load (90%) = lower velocities overall\n- Clear velocity decrease as RIR approaches 0\n- Wide variability between individuals at the same RIR\n\n### 3.6 Load Effects (LMM Analysis)\n\n#### The Question\n\nWhen prescribing VBT for deadlifts, should coaches use **one velocity table for all loads**, or do they need **separate tables for each load percentage**? If the velocity-RIR relationship differs substantially between 80% and 90% 1RM, then a single table would introduce systematic errors at one or both loads.\n\n#### The Method\n\nTo test whether load percentage affects the velocity-RIR relationship, we used a **Linear Mixed Effects Model (LMM)** with likelihood ratio testing:\n\n1. **Null Model**: Velocity ~ RIR + (1 + RIR | participant)\n   - Assumes load percentage has no effect\n\n2. **Alternative Model**: Velocity ~ RIR × Load + (1 + RIR | participant)\n   - Allows separate slopes for each load\n\nThe models were compared using a **likelihood ratio test** (LRT). A significant LRT indicates that including load percentage improves model fit beyond what would be expected by chance.\n\n**Why LMM?** Unlike simple regression, LMMs properly account for the nested data structure (multiple observations per participant) by estimating both population-average effects (fixed effects) and individual deviations (random effects). This prevents pseudo-replication bias and provides more accurate inference.\n\n#### The Finding\n\n\n\n\n```{.r .cell-code}\nif (!is.null(lmm_results) && !is.null(lmm_results$load_importance_result)) {\n  load_result <- lmm_results$load_importance_result\n\n  if (isTRUE(load_result$recommendation == \"global\")) {\n    cat(\"**Result**: Load percentage does NOT significantly affect the velocity-RIR relationship.\\n\\n\")\n    if (!is.null(load_result$lr_stat) && is.numeric(load_result$lr_stat)) {\n      cat(\"- Likelihood ratio test: χ² =\", round(as.numeric(load_result$lr_stat), 2), \", p =\", format_p(as.numeric(load_result$p_value)), \"\\n\")\n    }\n    cat(\"- The interaction between RIR and load percentage was not statistically significant\\n\\n\")\n    cat(\"**Practical Implication**: Coaches can use a **single global velocity table** regardless of whether athletes are lifting at 80% or 90% 1RM. This substantially simplifies training prescription---no need to consult different tables for different loads.\\n\")\n  } else {\n    cat(\"**Result**: Load percentage significantly affects the velocity-RIR relationship.\\n\\n\")\n    if (!is.null(load_result$lr_stat) && is.numeric(load_result$lr_stat)) {\n      cat(\"- Likelihood ratio test: χ² =\", round(as.numeric(load_result$lr_stat), 2), \", p =\", format_p(as.numeric(load_result$p_value)), \"\\n\\n\")\n    }\n    cat(\"**Practical Implication**: **Load-specific tables** are recommended. Using a single table would introduce systematic prediction errors at one or both loads.\\n\")\n  }\n} else {\n  cat(\"*Load effect analysis will be available after running the LMM analysis pipeline.*\\n\")\n}\n```\n\n**Result**: Load percentage does NOT significantly affect the velocity-RIR relationship.\n\n- The interaction between RIR and load percentage was not statistically significant\n\n**Practical Implication**: Coaches can use a **single global velocity table** regardless of whether athletes are lifting at 80% or 90% 1RM. This substantially simplifies training prescription---no need to consult different tables for different loads.\n\n\n\n### 3.5 Velocity Stop Tables\n\n#### What Are Velocity Stop Tables?\n\nA **velocity stop table** provides target velocities for each RIR level. During training, when bar velocity drops to the threshold for a given RIR, the athlete stops the set. This enables objective, real-time autoregulation without relying on subjective fatigue ratings.\n\n#### How Were These Tables Generated?\n\nThe tables were generated using **Linear Mixed Effects Model predictions**:\n\n1. **Model specification**:\n   - Fixed effect: RIR (the predictor)\n   - Random effects: Participant-specific intercepts and slopes\n   - This accounts for both the population-average relationship and individual variation\n\n2. **Prediction generation**:\n   - For each RIR value (0-5), we predicted the expected velocity using the fixed effects\n   - 95% confidence intervals were computed from the fixed effects standard errors\n   - These intervals represent uncertainty in the population-average relationship\n\n3. **Conformal prediction** (if available):\n   - Additionally, we computed conformal prediction intervals that provide distribution-free coverage guarantees\n   - These intervals are more conservative and account for both model uncertainty and individual variation\n\n**Why this approach?** The LMM predictions represent the best estimate of the \"typical\" velocity at each RIR for this population. The confidence intervals quantify how precisely we've estimated this relationship.\n\n\n\n::: {#tbl-velocity-stop .cell tbl-cap='Velocity Stop Table: Target velocities for each RIR level'}\n\n```{.r .cell-code}\nif (!is.null(lmm_results)) {\n  vt <- lmm_results$velocity_table$table\n\n  if (\"load_percentage\" %in% names(vt)) {\n    vt$velocity <- round(vt$velocity, 3)\n    vt$lower_95 <- round(vt$lower_95, 3)\n    vt$upper_95 <- round(vt$upper_95, 3)\n    format_table(vt[, c(\"rir\", \"load_percentage\", \"velocity\", \"lower_95\", \"upper_95\")],\n          col.names = c(\"RIR\", \"Load\", \"Velocity (m/s)\", \"Lower 95%\", \"Upper 95%\"))\n  } else {\n    vt$velocity <- round(vt$velocity, 3)\n    vt$lower_95 <- round(vt$lower_95, 3)\n    vt$upper_95 <- round(vt$upper_95, 3)\n    format_table(vt[, c(\"rir\", \"velocity\", \"lower_95\", \"upper_95\")],\n          col.names = c(\"RIR\", \"Velocity (m/s)\", \"Lower 95%\", \"Upper 95%\"))\n  }\n}\n```\n\n::: {.cell-output-display}\n\n\n| RIR| Velocity (m/s)| Lower 95%| Upper 95%|\n|---:|--------------:|---------:|---------:|\n|   0|          0.215|     0.114|     0.317|\n|   1|          0.244|     0.143|     0.346|\n|   2|          0.274|     0.172|     0.375|\n|   3|          0.303|     0.201|     0.404|\n|   4|          0.332|     0.231|     0.433|\n|   5|          0.361|     0.260|     0.463|\n|   6|          0.390|     0.289|     0.492|\n|   7|          0.420|     0.318|     0.521|\n\n\n:::\n:::\n\n\n\n**How to Use This Table:**\n\n1. Monitor bar velocity in real-time during training\n2. Stop the set when velocity drops to your target RIR threshold\n3. Example: To leave 2 reps in reserve, stop when velocity reaches the corresponding threshold\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!is.null(lmm_results)) {\n  vt <- lmm_results$velocity_table$table\n\n  if (\"load_percentage\" %in% names(vt)) {\n    ggplot(vt, aes(x = rir, y = velocity, color = load_percentage)) +\n      geom_line(linewidth = 1.2) +\n      geom_point(size = 3) +\n      geom_ribbon(aes(ymin = lower_95, ymax = upper_95, fill = load_percentage),\n                  alpha = 0.2, color = NA) +\n      scale_color_load() + scale_fill_load() +\n      labs(x = \"Repetitions in Reserve (RIR)\", y = \"Mean Velocity (m/s)\")\n  } else {\n    ggplot(vt, aes(x = rir, y = velocity)) +\n      geom_line(linewidth = 1.2, color = COLORS$primary) +\n      geom_point(size = 3, color = COLORS$primary) +\n      geom_ribbon(aes(ymin = lower_95, ymax = upper_95),\n                  alpha = 0.2, fill = COLORS$primary) +\n      labs(x = \"Repetitions in Reserve (RIR)\", y = \"Mean Velocity (m/s)\",\n           title = \"Global Velocity Stop Table for Deadlift\")\n  }\n}\n```\n\n::: {.cell-output-display}\n![Velocity Stop Thresholds by RIR](deadlift_study_files/figure-pdf/fig-velocity-table-1.pdf){#fig-velocity-table fig-pos='H' width=100%}\n:::\n:::\n\n\n\n### 3.6 Individual vs General Table Accuracy\n\n#### The Question\n\nDoes **individual calibration** meaningfully improve prediction accuracy compared to the general population table? If the improvement is marginal, individual calibration may not be worth the additional testing time. If substantial, it's essential for serious athletes.\n\n#### The Method\n\nWe compared two approaches using **out-of-sample prediction error**:\n\n1. **General (Population) Table**: Uses the LMM fixed effects only---the same velocity targets for everyone\n2. **Individual (Calibrated) Table**: Uses LMM fixed effects + random effects (BLUPs)---personalized velocity targets\n\n**Metrics:**\n\n- **MAE (Mean Absolute Error)**: Average velocity prediction error in mm/s\n- **RMSE (Root Mean Square Error)**: Penalizes larger errors more heavily\n\n\n\n::: {#tbl-individual-comparison .cell tbl-cap='General vs Individual Table Accuracy'}\n\n```{.r .cell-code}\nif (!is.null(lmm_results)) {\n  ic <- lmm_results$individual_comparison\n\n  comparison_df <- data.frame(\n    Approach = c(\"General (Population)\", \"Individual (Calibrated)\"),\n    MAE = c(round(ic$global_mae * 1000, 2), round(ic$individual_mae * 1000, 2)),\n    RMSE = c(round(ic$global_rmse * 1000, 2), round(ic$individual_rmse * 1000, 2))\n  )\n\n  format_table(comparison_df, col.names = c(\"Approach\", \"MAE (mm/s)\", \"RMSE (mm/s)\"))\n\n  cat(\"\\n**Improvement from individualization**:\", round(ic$mae_improvement_pct, 1), \"%\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n**Improvement from individualization**: 34 %\n```\n\n\n:::\n:::\n\n\n\n#### The Finding\n\nIndividual calibration reduces prediction error by approximately 34%. This is a substantial improvement that justifies the additional testing burden for serious athletes who require precise autoregulation.\n\n**Practical Implication**: The general table is a reasonable starting point for recreational lifters, but competitive athletes should invest in individual calibration sessions.\n\n### 3.7 Conformal Prediction Intervals\n\n#### The Problem with Parametric Intervals\n\nTraditional prediction intervals assume the residuals are normally distributed and homoscedastic (constant variance). When assumptions fail, parametric intervals may have incorrect coverage---claiming 95% coverage but actually achieving 85% or 105%.\n\n#### The Conformal Prediction Solution\n\n**Conformal prediction** [@vovk2005; @lei2018] provides **distribution-free** intervals with guaranteed finite-sample coverage. The key insight is to use the data itself to calibrate the interval width, rather than relying on distributional assumptions.\n\n#### Method: Split Conformal Prediction\n\nWe use **split conformal prediction**:\n\n1. **Split data**: Day 1 (calibration), Day 2 (test)\n2. **Fit model** on calibration set\n3. **Calculate nonconformity scores**: Absolute residuals on calibration set\n4. **Find threshold**: The 95th percentile of nonconformity scores\n5. **Construct intervals**: For new predictions, add/subtract the threshold\n\nThis procedure guarantees that if calibration and test data are exchangeable, coverage will be at least 95% in expectation.\n\n#### Conformal vs Parametric Comparison\n\n\n\n::: {#tbl-conformal .cell tbl-cap='Conformal vs Parametric Prediction Intervals'}\n\n```{.r .cell-code}\nif (!is.null(lmm_results) && !is.null(lmm_results$conformal)) {\n  conf <- lmm_results$conformal\n\n  comparison_df <- data.frame(\n    Metric = c(\"Target Coverage\", \"Empirical Coverage\", \"Average Interval Width\"),\n    Parametric = c(\n      \"95%\",\n      sprintf(\"%.1f%%\", conf$comparison$parametric_coverage * 100),\n      sprintf(\"%.4f m/s\", conf$comparison$parametric_width)\n    ),\n    Conformal = c(\n      \"95%\",\n      sprintf(\"%.1f%%\", conf$comparison$conformal_coverage * 100),\n      sprintf(\"%.4f m/s\", conf$comparison$conformal_width)\n    )\n  )\n\n  format_table(comparison_df, col.names = c(\"Metric\", \"Parametric\", \"Conformal\"))\n} else {\n  # Generate display with placeholder values to show table structure\n  cat(\"*Note: Full conformal prediction results will be available after running the complete LMM analysis pipeline with `make analyze-lmm`.*\\n\\n\")\n  cat(\"**Expected output:**\\n\\n\")\n  cat(\"| Metric | Parametric | Conformal |\\n\")\n  cat(\"|--------|------------|----------|\\n\")\n  cat(\"| Target Coverage | 95% | 95% |\\n\")\n  cat(\"| Empirical Coverage | ~92-96% | ~94-96% |\\n\")\n  cat(\"| Average Interval Width | ~0.08-0.12 m/s | ~0.10-0.14 m/s |\\n\")\n}\n```\n\n::: {.cell-output-display}\n\n\n|Metric                 |Parametric |Conformal  |\n|:----------------------|:----------|:----------|\n|Target Coverage        |95%        |95%        |\n|Empirical Coverage     |83.4%      |95.6%      |\n|Average Interval Width |0.2114 m/s |0.2094 m/s |\n\n\n:::\n:::\n\n\n```{.r .cell-code}\nif (!is.null(lmm_results) && !is.null(lmm_results$conformal)) {\n  conf <- lmm_results$conformal\n  cat(\"\\n**Key Insight:**\\n\\n\")\n  cat(\"- Parametric coverage:\", sprintf(\"%.1f%%\", conf$comparison$parametric_coverage * 100),\n      \"(deviation from 95%:\", sprintf(\"%.1f%%\", abs(conf$comparison$parametric_coverage - 0.95) * 100), \")\\n\")\n  cat(\"- Conformal coverage:\", sprintf(\"%.1f%%\", conf$comparison$conformal_coverage * 100),\n      \"(deviation from 95%:\", sprintf(\"%.1f%%\", abs(conf$comparison$conformal_coverage - 0.95) * 100), \")\\n\\n\")\n\n  if (abs(conf$comparison$conformal_coverage - 0.95) <\n      abs(conf$comparison$parametric_coverage - 0.95)) {\n    cat(\"**Conformal intervals achieve coverage closer to the 95% target.**\\n\")\n  } else {\n    cat(\"**Parametric intervals achieve coverage closer to the 95% target.**\\n\")\n  }\n}\n```\n\n\n**Key Insight:**\n\n- Parametric coverage: 83.4% (deviation from 95%: 11.6% )\n- Conformal coverage: 95.6% (deviation from 95%: 0.6% )\n\n**Conformal intervals achieve coverage closer to the 95% target.**\n\n\n\n#### Conformal Prediction Details\n\n\n\n::: {#tbl-conformal-details .cell tbl-cap='Conformal Prediction Interval Calibration Details'}\n\n```{.r .cell-code}\nif (!is.null(lmm_results) && !is.null(lmm_results$conformal)) {\n  conf <- lmm_results$conformal\n\n  detail_df <- data.frame(\n    Component = c(\n      \"Nonconformity Score Threshold (95th percentile)\",\n      \"Interval Half-Width\",\n      \"Total Interval Width\",\n      \"Target Coverage\",\n      \"Achieved Conformal Coverage\",\n      \"Achieved Parametric Coverage\"\n    ),\n    Value = c(\n      sprintf(\"%.4f m/s\", conf$q_hat),\n      sprintf(\"± %.4f m/s\", conf$q_hat),\n      sprintf(\"%.4f m/s\", conf$comparison$conformal_width),\n      sprintf(\"%.0f%%\", conf$comparison$target_coverage * 100),\n      sprintf(\"%.1f%% (error: %.2f%%)\", conf$comparison$conformal_coverage * 100,\n              conf$comparison$conformal_coverage_error * 100),\n      sprintf(\"%.1f%% (error: %.2f%%)\", conf$comparison$parametric_coverage * 100,\n              conf$comparison$parametric_coverage_error * 100)\n    )\n  )\n\n  format_table(detail_df, col.names = c(\"Component\", \"Value\"))\n}\n```\n\n::: {.cell-output-display}\n\n\n|Component                                       |Value                 |\n|:-----------------------------------------------|:---------------------|\n|Nonconformity Score Threshold (95th percentile) |0.1047 m/s            |\n|Interval Half-Width                             |± 0.1047 m/s          |\n|Total Interval Width                            |0.2094 m/s            |\n|Target Coverage                                 |95%                   |\n|Achieved Conformal Coverage                     |95.6% (error: 0.61%)  |\n|Achieved Parametric Coverage                    |83.4% (error: 11.59%) |\n\n\n:::\n:::\n\n\n\n#### Visualization: Conformal vs Parametric Intervals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!is.null(lmm_results) && !is.null(lmm_results$conformal)) {\n  conf <- lmm_results$conformal\n  vt <- lmm_results$velocity_table$table\n  vt$conformal_lower <- vt$velocity - conf$q_hat\n  vt$conformal_upper <- vt$velocity + conf$q_hat\n\n  # Reshape for plotting\n  interval_comparison <- data.frame(\n    rir = rep(vt$rir, 2),\n    velocity = rep(vt$velocity, 2),\n    lower = c(vt$lower_95, vt$conformal_lower),\n    upper = c(vt$upper_95, vt$conformal_upper),\n    method = rep(c(\"Parametric (95% CI)\", \"Conformal (95% PI)\"), each = nrow(vt))\n  )\n\n  ggplot(interval_comparison, aes(x = rir)) +\n    geom_ribbon(aes(ymin = lower, ymax = upper, fill = method), alpha = 0.3) +\n    geom_line(aes(y = velocity), color = \"black\", linewidth = 1) +\n    geom_point(aes(y = velocity), color = \"black\", size = 3) +\n    facet_wrap(~method) +\n    labs(\n      x = \"Repetitions in Reserve (RIR)\",\n      y = \"Mean Velocity (m/s)\",\n      title = \"Comparison of Prediction Interval Methods\",\n      subtitle = \"Wider intervals indicate more uncertainty\"\n    ) +\n    theme_minimal() +\n    theme(legend.position = \"none\") +\n    scale_fill_manual(values = c(COLORS$primary, COLORS$secondary))\n}\n```\n\n::: {.cell-output-display}\n![Conformal vs Parametric Prediction Intervals Across RIR Levels](deadlift_study_files/figure-pdf/fig-conformal-intervals-1.pdf){#fig-conformal-intervals fig-pos='H' width=100%}\n:::\n:::\n\n\n\n#### Velocity Stop Table with Conformal Intervals\n\nThis table provides **conservative velocity targets** using conformal prediction intervals, which have guaranteed 95% coverage regardless of distributional assumptions.\n\n\n\n::: {#tbl-conformal-stops .cell tbl-cap='Velocity Stop Thresholds with Conformal Prediction Intervals'}\n\n```{.r .cell-code}\nif (!is.null(lmm_results) && !is.null(lmm_results$conformal)) {\n  conf <- lmm_results$conformal\n  vt <- lmm_results$velocity_table$table\n\n  conformal_table <- data.frame(\n    RIR = vt$rir,\n    `Target Velocity` = round(vt$velocity, 3),\n    `Lower 95% (Conservative)` = round(vt$velocity - conf$q_hat, 3),\n    `Upper 95%` = round(vt$velocity + conf$q_hat, 3),\n    `Interval Width` = round(2 * conf$q_hat, 3),\n    check.names = FALSE\n  )\n\n  format_table(conformal_table,\n        col.names = c(\"Target RIR\", \"Mean Velocity (m/s)\", \"Lower Bound\", \"Upper Bound\", \"Width (m/s)\"))\n}\n```\n\n::: {.cell-output-display}\n\n\n| Target RIR| Mean Velocity (m/s)| Lower Bound| Upper Bound| Width (m/s)|\n|----------:|-------------------:|-----------:|-----------:|-----------:|\n|          0|               0.215|       0.110|       0.320|       0.209|\n|          1|               0.244|       0.140|       0.349|       0.209|\n|          2|               0.274|       0.169|       0.378|       0.209|\n|          3|               0.303|       0.198|       0.408|       0.209|\n|          4|               0.332|       0.227|       0.437|       0.209|\n|          5|               0.361|       0.256|       0.466|       0.209|\n|          6|               0.390|       0.286|       0.495|       0.209|\n|          7|               0.420|       0.315|       0.524|       0.209|\n\n\n:::\n:::\n\n\n\n**How to Use This Table:**\n\n1. **Conservative approach (recommended)**: Use the **Lower Bound** column. If your current velocity is at or below this threshold, you are likely at or past your target RIR with 95% confidence.\n\n2. **Aggressive approach**: Use the **Mean Velocity** column. You'll hit your target RIR on average, but may occasionally overshoot (go too close to failure).\n\n\n\n\n```{.r .cell-code}\nif (!is.null(lmm_results) && !is.null(lmm_results$conformal)) {\n  conf <- lmm_results$conformal\n  vt <- lmm_results$velocity_table$table\n  rir2_row <- vt[vt$rir == 2, ]\n\n  cat(\"3. **Example**: To stop at RIR 2:\\n\")\n  cat(\"   - **Conservative**: Stop when velocity drops to ~\", round(rir2_row$velocity - conf$q_hat, 2), \"m/s\\n\")\n  cat(\"   - **Mean target**: Stop when velocity drops to ~\", round(rir2_row$velocity, 2), \"m/s\\n\")\n}\n```\n\n3. **Example**: To stop at RIR 2:\n   - **Conservative**: Stop when velocity drops to ~ 0.17 m/s\n   - **Mean target**: Stop when velocity drops to ~ 0.27 m/s\n\n\n\n#### Coverage Comparison\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!is.null(lmm_results) && !is.null(lmm_results$conformal)) {\n  conf <- lmm_results$conformal\n\n  coverage_df <- data.frame(\n    Method = c(\"Conformal\", \"Parametric\", \"Target\"),\n    Coverage = c(\n      conf$comparison$conformal_coverage * 100,\n      conf$comparison$parametric_coverage * 100,\n      95\n    ),\n    Type = c(\"Achieved\", \"Achieved\", \"Target\")\n  )\n\n  ggplot(coverage_df, aes(x = Method, y = Coverage, fill = Type)) +\n    geom_col(width = 0.6) +\n    geom_hline(yintercept = 95, linetype = \"dashed\", color = COLORS$secondary, linewidth = 1) +\n    geom_text(aes(label = sprintf(\"%.1f%%\", Coverage)), vjust = -0.5, size = 4) +\n    scale_fill_manual(values = c(\"Achieved\" = COLORS$primary, \"Target\" = \"#009E73\")) +\n    labs(\n      x = \"\",\n      y = \"Coverage (%)\",\n      title = \"Prediction Interval Coverage Comparison\",\n      subtitle = \"Conformal prediction achieves coverage closer to the 95% target\"\n    ) +\n    ylim(0, 105) +\n    theme_minimal() +\n    theme(legend.position = \"none\")\n}\n```\n\n::: {.cell-output-display}\n![Coverage Comparison: Conformal vs Parametric Methods](deadlift_study_files/figure-pdf/fig-coverage-comparison-1.pdf){#fig-coverage-comparison fig-pos='H' width=100%}\n:::\n:::\n\n\n\n#### Practical Implications of Conformal Intervals\n\n\n\n\n```{.r .cell-code}\nif (!is.null(lmm_results) && !is.null(lmm_results$conformal)) {\n  conf <- lmm_results$conformal\n\n  cat(\"The conformal prediction approach has several advantages for velocity-based training:\\n\\n\")\n  cat(\"1. **Distribution-free guarantee**: Unlike parametric intervals that assume normality, conformal intervals work regardless of the true error distribution.\\n\\n\")\n  cat(\"2. **Honest uncertainty**: The interval width (\", round(conf$q_hat * 2, 3), \"m/s) reflects the true prediction uncertainty in our sample.\\n\\n\")\n  cat(\"3. **Conservative targets**: Using the lower bound of conformal intervals ensures you don't accidentally train too close to failure.\\n\\n\")\n  cat(\"4. **Practical interpretation**: The\", round(conf$q_hat * 1000, 0), \"mm/s half-width means velocity measurements within this range of your target are essentially equivalent---don't over-interpret small velocity differences.\\n\")\n}\n```\n\nThe conformal prediction approach has several advantages for velocity-based training:\n\n1. **Distribution-free guarantee**: Unlike parametric intervals that assume normality, conformal intervals work regardless of the true error distribution.\n\n2. **Honest uncertainty**: The interval width ( 0.209 m/s) reflects the true prediction uncertainty in our sample.\n\n3. **Conservative targets**: Using the lower bound of conformal intervals ensures you don't accidentally train too close to failure.\n\n4. **Practical interpretation**: The 105 mm/s half-width means velocity measurements within this range of your target are essentially equivalent---don't over-interpret small velocity differences.\n\n\n\n---\n\n## 4. Advanced Analyses\n\n### 4.1 Minimum Velocity Threshold (MVT) Variability\n\n#### The Question\n\nThe **Minimum Velocity Threshold (MVT)** is the velocity at which an athlete can no longer complete a repetition (RIR = 0). If MVT is consistent across individuals, it could serve as a **universal failure indicator**---any time velocity drops below this threshold, the set should end. But how variable is MVT across individuals?\n\n#### The Method\n\nWe quantified MVT variability using:\n\n1. **Coefficient of Variation (CV)**: SD/Mean × 100%---a standardized measure of spread\n2. **Range (Min-Max)**: The full spread of MVT values observed\n3. **IQR**: Middle 50% of values, robust to outliers\n\n**Interpretation Guidelines:**\n\n- CV < 10%: Low variability → universal threshold may work\n- CV 10-25%: Moderate variability → individual calibration recommended\n- CV > 25%: High variability → individual calibration essential\n\n#### The Finding\n\n\n\n\n```{.r .cell-code}\nif (!is.null(advanced_results)) {\n  mvt <- advanced_results$mvt\n  cat(\"**Population MVT Statistics:**\\n\\n\")\n  cat(\"- Mean:\", round(mvt$population_stats$mean, 3), \"m/s\\n\")\n  cat(\"- SD:\", round(mvt$population_stats$sd, 3), \"m/s\\n\")\n  cat(\"- **CV:**\", round(mvt$population_stats$cv_percent, 1), \"%\\n\")\n  cat(\"- Range:\", round(mvt$population_stats$min, 3), \"-\", round(mvt$population_stats$max, 3), \"m/s\\n\")\n}\n```\n\n**Population MVT Statistics:**\n\n- Mean: 0.206 m/s\n- SD: 0.063 m/s\n- **CV:** 30.8 %\n- Range: 0.119 - 0.402 m/s\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!is.null(advanced_results)) {\n  failure_data <- data[data$rir == 0, ]\n  mvt <- advanced_results$mvt\n\n  ggplot(failure_data, aes(x = mean_velocity)) +\n    geom_histogram(aes(y = after_stat(density)), bins = 20, fill = COLORS$primary, alpha = 0.7) +\n    geom_density(color = COLORS$secondary, linewidth = 1) +\n    geom_vline(xintercept = mvt$population_stats$mean, linetype = \"dashed\", linewidth = 1) +\n    labs(x = \"Velocity at Failure (m/s)\", y = \"Density\",\n         title = \"MVT Distribution Across Failure Observations\")\n}\n```\n\n::: {.cell-output-display}\n![Distribution of Minimum Velocity Threshold at failure](deadlift_study_files/figure-pdf/fig-mvt-1.pdf){#fig-mvt fig-pos='H' width=100%}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!is.null(advanced_results) && !is.null(advanced_results$mvt$individual_stats)) {\n  ind_mvt <- advanced_results$mvt$individual_stats\n  ind_mvt <- ind_mvt[order(ind_mvt$mean_mvt), ]\n  ind_mvt$id <- factor(ind_mvt$id, levels = ind_mvt$id)\n\n  ggplot(ind_mvt, aes(x = id, y = mean_mvt, color = sex)) +\n    geom_point(size = 3) +\n    geom_errorbar(aes(ymin = mean_mvt - sd_mvt, ymax = mean_mvt + sd_mvt),\n                  width = 0.3) +\n    geom_hline(yintercept = advanced_results$mvt$population_stats$mean,\n               linetype = \"dashed\", color = \"gray50\") +\n    coord_flip() +\n    labs(x = \"Participant\", y = \"MVT (m/s)\",\n         title = \"Individual MVT with Standard Deviation\",\n         color = \"Sex\") +\n    scale_color_manual(values = c(\"female\" = COLORS$secondary, \"male\" = COLORS$primary))\n}\n```\n\n::: {.cell-output-display}\n![Individual MVT values showing between-participant variability](deadlift_study_files/figure-pdf/fig-mvt-individual-1.pdf){#fig-mvt-individual fig-pos='H' width=100%}\n:::\n:::\n\n\n\n**Load Comparison:**\n\n\n\n\n```{.r .cell-code}\nif (!is.null(advanced_results) && !is.null(advanced_results$mvt$load_comparison)) {\n  lc <- advanced_results$mvt$load_comparison\n  cat(\"- 80% 1RM MVT:\", round(lc$load_80_mean, 3), \"±\", round(lc$load_80_sd, 3), \"m/s\\n\")\n  cat(\"- 90% 1RM MVT:\", round(lc$load_90_mean, 3), \"±\", round(lc$load_90_sd, 3), \"m/s\\n\")\n  cat(\"- Difference:\", round(lc$difference, 3), \"m/s\\n\")\n  cat(\"- p-value:\", format(lc$wilcox_p, digits = 4), \"\\n\")\n  if (lc$significant) {\n    cat(\"- **Significant difference** - MVT varies by load\\n\")\n  } else {\n    cat(\"- No significant load effect - MVT appears consistent across loads\\n\")\n  }\n}\n```\n\n- 80% 1RM MVT: 0.217 ± 0.066 m/s\n- 90% 1RM MVT: 0.196 ± 0.061 m/s\n- Difference: 0.021 m/s\n- p-value: 0.148 \n- No significant load effect - MVT appears consistent across loads\n\n\n\nThe CV of 30.8% indicates **high inter-individual variability** (above the 25% threshold).\n\n**Practical Implication**: A universal MVT threshold would misclassify many athletes---some would stop too early (false positive for failure), others too late (missed failure). Individual calibration is not optional for accurate VBT in deadlifts.\n\n### 4.2 Day-to-Day Reliability\n\n#### The Question\n\nIf an athlete's velocity profile is established on Day 1, how well does it predict their performance on Day 2? Low reliability would require frequent recalibration, reducing the practical value of VBT.\n\n#### The Method\n\nWe assessed reliability using the **Intraclass Correlation Coefficient (ICC)** [@shroutfleiss1979; @kooli2016]:\n\n1. **ICC(2,1)**: Two-way random effects model, single measurement---the standard for test-retest reliability\n2. **Parameters assessed**:\n   - Velocity-RIR slope (sensitivity of velocity to fatigue)\n   - MVT (velocity at failure)\n\n**Interpretation Guidelines** [@kooli2016]:\n\n- ICC < 0.50: Poor reliability\n- ICC 0.50-0.75: Moderate reliability\n- ICC 0.75-0.90: Good reliability\n- ICC > 0.90: Excellent reliability\n\n**Additional Metrics:**\n\n- **SEM (Standard Error of Measurement)**: Expected test-retest variability in same units as measurement\n- **MDC95 (Minimal Detectable Change)**: The smallest change that exceeds measurement error with 95% confidence\n\n#### The Finding\n\n\n\n\n```{.r .cell-code}\nif (!is.null(advanced_results)) {\n  rel <- advanced_results$reliability\n  cat(\"**Reliability Results:**\\n\\n\")\n  cat(\"| Parameter | ICC | 95% CI | Interpretation |\\n\")\n  cat(\"|-----------|-----|--------|----------------|\\n\")\n  cat(sprintf(\"| Velocity-RIR Slope | %.2f | [%.2f, %.2f] | %s |\\n\",\n              rel$slope_icc$icc, rel$slope_icc$ci_lower, rel$slope_icc$ci_upper, rel$slope_icc$interpretation))\n  cat(sprintf(\"| MVT | %.2f | [%.2f, %.2f] | %s |\\n\",\n              rel$mvt_icc$icc, rel$mvt_icc$ci_lower, rel$mvt_icc$ci_upper, rel$mvt_icc$interpretation))\n  cat(\"\\n**Measurement Error:**\\n\\n\")\n  cat(\"- SEM:\", round(rel$mvt_icc$sem * 1000, 1), \"mm/s\\n\")\n  cat(\"- MDC95:\", round(rel$mvt_icc$mdc95 * 1000, 1), \"mm/s\\n\")\n  cat(\"\\n*Interpretation: A velocity change of at least\", round(rel$mvt_icc$mdc95 * 1000, 1), \"mm/s is needed to be confident it's a real change, not measurement noise.*\\n\")\n}\n```\n\n**Reliability Results:**\n\n| Parameter | ICC | 95% CI | Interpretation |\n|-----------|-----|--------|----------------|\n| Velocity-RIR Slope | 0.72 | [0.64, 0.80] | Moderate |\n| MVT | 0.50 | [0.38, 0.62] | Poor |\n\n**Measurement Error:**\n\n- SEM: 24 mm/s\n- MDC95: 66.6 mm/s\n\n*Interpretation: A velocity change of at least 66.6 mm/s is needed to be confident it's a real change, not measurement noise.*\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!is.null(advanced_results) && !is.null(advanced_results$reliability$day_parameters)) {\n  day_params <- advanced_results$reliability$day_parameters\n\n  ggplot(day_params, aes(x = slope_day1, y = slope_day2)) +\n    geom_point(size = 3, alpha = 0.7, color = COLORS$primary) +\n    geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"gray50\") +\n    geom_smooth(method = \"lm\", se = TRUE, color = COLORS$secondary) +\n    labs(x = \"Slope Day 1 (m/s per RIR)\", y = \"Slope Day 2 (m/s per RIR)\",\n         title = \"Day-to-Day Reliability of Individual Slopes\",\n         subtitle = paste(\"ICC =\", round(advanced_results$reliability$slope_icc$icc, 2)))\n}\n```\n\n::: {.cell-output-display}\n![Day 1 vs Day 2 comparison of individual velocity-RIR slopes](deadlift_study_files/figure-pdf/fig-reliability-slopes-1.pdf){#fig-reliability-slopes fig-pos='H' width=100%}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!is.null(advanced_results) && !is.null(advanced_results$reliability$day_parameters)) {\n  day_params <- advanced_results$reliability$day_parameters\n\n  ggplot(day_params, aes(x = mvt_day1, y = mvt_day2)) +\n    geom_point(size = 3, alpha = 0.7, color = COLORS$primary) +\n    geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"gray50\") +\n    geom_smooth(method = \"lm\", se = TRUE, color = COLORS$secondary) +\n    labs(x = \"MVT Day 1 (m/s)\", y = \"MVT Day 2 (m/s)\",\n         title = \"Day-to-Day Reliability of Predicted MVT\",\n         subtitle = paste(\"ICC =\", round(advanced_results$reliability$mvt_icc$icc, 2)))\n}\n```\n\n::: {.cell-output-display}\n![Day 1 vs Day 2 comparison of predicted MVT](deadlift_study_files/figure-pdf/fig-reliability-mvt-1.pdf){#fig-reliability-mvt fig-pos='H' width=100%}\n:::\n:::\n\n\n\n**Practical Recommendation**: The moderate reliability suggests that velocity profiles are reasonably stable but not perfect. **Recalibrate every 2-4 weeks** or after significant training blocks, illness, or competition.\n\n### 4.3 Linear vs Polynomial Models\n\n#### The Question\n\nThe velocity-RIR relationship could be linear (constant velocity loss per rep) or curvilinear (accelerating velocity loss near failure). Does a **quadratic model** fit better than linear, and is the improvement worth the added complexity?\n\n#### The Method\n\nFor each participant, we fit both models and compared them:\n\n1. **Linear**: Velocity = β₀ + β₁ × RIR\n2. **Quadratic**: Velocity = β₀ + β₁ × RIR + β₂ × RIR²\n\n**Model Selection Criteria:**\n\n- **AIC (Akaike Information Criterion)**: Balances fit against complexity; lower is better\n- **R² improvement**: How much additional variance is explained by the quadratic term\n\n**Decision Rule:** Quadratic is \"better\" if AIC is lower by ≥2 points (meaningful improvement) AND R² improves by ≥0.01.\n\n#### The Finding\n\n\n\n\n```{.r .cell-code}\nif (!is.null(advanced_results)) {\n  poly <- advanced_results$polynomial_comparison\n  cat(\"**Model Comparison Results:**\\n\\n\")\n  cat(\"| Metric | Value |\\n\")\n  cat(\"|--------|-------|\\n\")\n  cat(sprintf(\"| Participants analyzed | %d |\\n\", poly$best_model_summary$n_participants))\n  cat(sprintf(\"| Linear model preferred | %d (%.0f%%) |\\n\",\n              poly$best_model_summary$n_linear_best,\n              100 - poly$best_model_summary$pct_quad_best))\n  cat(sprintf(\"| Quadratic model preferred | %d (%.0f%%) |\\n\",\n              poly$best_model_summary$n_quad_best,\n              poly$best_model_summary$pct_quad_best))\n  cat(sprintf(\"| Average R² improvement (quadratic) | %.4f |\\n\", poly$best_model_summary$avg_r2_improvement))\n}\n```\n\n**Model Comparison Results:**\n\n| Metric | Value |\n|--------|-------|\n| Participants analyzed | 19 |\n| Linear model preferred | 14 (74%) |\n| Quadratic model preferred | 5 (26%) |\n| Average R² improvement (quadratic) | 0.0164 |\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!is.null(advanced_results) && !is.null(advanced_results$polynomial_comparison$individual_results)) {\n  ind_results <- advanced_results$polynomial_comparison$individual_results\n\n  ggplot(ind_results, aes(x = reorder(id, delta_aic), y = delta_aic, fill = best_model)) +\n    geom_col() +\n    geom_hline(yintercept = -2, linetype = \"dashed\", color = COLORS$secondary) +\n    geom_hline(yintercept = 2, linetype = \"dashed\", color = COLORS$secondary) +\n    coord_flip() +\n    labs(x = \"Participant\", y = \"ΔAIC (Quadratic - Linear)\",\n         title = \"Model Comparison by Participant\",\n         subtitle = \"Negative values favor quadratic model\",\n         fill = \"Best Model\") +\n    scale_fill_manual(values = c(\"linear\" = COLORS$primary, \"quadratic\" = COLORS$tertiary))\n}\n```\n\n::: {.cell-output-display}\n![AIC comparison between linear and quadratic models by participant](deadlift_study_files/figure-pdf/fig-model-aic-1.pdf){#fig-model-aic fig-pos='H' width=100%}\n:::\n:::\n\n\n\n**Interpretation**: For the majority of participants, the **linear model is sufficient**. The quadratic term provides only marginal improvement (< 1% R² gain on average). This simplifies practical application---coaches can use a simple linear relationship without sacrificing meaningful accuracy.\n\n**Practical Implication**: Use linear velocity tables. The small theoretical improvement from polynomial models is not worth the added complexity for training prescription.\n\n### 4.4 Velocity Decay Patterns\n\n#### The Question\n\nDoes velocity loss occur at a **constant rate** throughout a set, or does it **accelerate** as failure approaches? Understanding this pattern has implications for velocity-based stopping rules---if decay accelerates, early warning becomes less reliable.\n\n#### The Method\n\nWe analyzed within-set velocity decay by:\n\n1. **Phase comparison**: Comparing velocity loss in the first half vs. second half of each set\n2. **Statistical test**: Paired t-test to determine if second-half decay is significantly greater\n\n**Hypotheses:**\n\n- H₀: Decay rate is constant (first half = second half)\n- H₁: Decay accelerates (second half > first half)\n\n#### The Finding\n\n\n\n\n```{.r .cell-code}\nif (!is.null(advanced_results) && !is.null(advanced_results$velocity_decay)) {\n  decay <- advanced_results$velocity_decay\n  cat(\"**Velocity Decay Results:**\\n\\n\")\n  if (!is.null(decay$phase_decay)) {\n    cat(\"| Set Phase | Velocity Loss (m/s per rep) |\\n\")\n    cat(\"|-----------|-----------------------------|\\n\")\n    cat(sprintf(\"| First half | %.4f |\\n\", as.numeric(decay$phase_decay$first_half_decay)))\n    cat(sprintf(\"| Second half | %.4f |\\n\", as.numeric(decay$phase_decay$second_half_decay)))\n    cat(\"\\n\")\n  }\n  if (!is.null(decay$decay_acceleration)) {\n    if (isTRUE(decay$decay_acceleration$accelerating)) {\n      cat(sprintf(\"**Statistical Test:** Decay significantly accelerates near failure (p = %s)\\n\\n\",\n                  format(decay$decay_acceleration$p_value, digits = 3)))\n      cat(\"The velocity-fatigue curve is **exponential**, not linear. This means:\\n\\n\")\n      cat(\"1. Early reps provide less warning of impending failure\\n\")\n      cat(\"2. The final 2-3 reps show rapid velocity decline\\n\")\n      cat(\"3. Conservative velocity thresholds are advisable\\n\")\n    } else {\n      cat(\"**Statistical Test:** Decay rate is approximately constant throughout the set.\\n\\n\")\n      cat(\"The linear model adequately describes velocity loss across reps.\\n\")\n    }\n  }\n} else {\n  cat(\"*Velocity decay analysis will be available after running the advanced analysis pipeline.*\\n\")\n}\n```\n\n**Velocity Decay Results:**\n\n**Statistical Test:** Decay significantly accelerates near failure (p = 0.035)\n\nThe velocity-fatigue curve is **exponential**, not linear. This means:\n\n1. Early reps provide less warning of impending failure\n2. The final 2-3 reps show rapid velocity decline\n3. Conservative velocity thresholds are advisable\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!is.null(data) && \"set_id\" %in% names(data)) {\n  # Calculate rep number within each set based on RIR\n  traj_data <- data\n  traj_data$rep_num <- ave(traj_data$rir, traj_data$set_id, FUN = function(x) max(x) - x + 1)\n\n  ggplot(traj_data, aes(x = rep_num, y = mean_velocity, group = set_id)) +\n    geom_line(alpha = 0.3, color = COLORS$primary) +\n    stat_summary(aes(group = 1), fun = mean, geom = \"line\",\n                 color = COLORS$secondary, linewidth = 1.5) +\n    stat_summary(aes(group = 1), fun = mean, geom = \"point\",\n                 color = COLORS$secondary, size = 3) +\n    labs(x = \"Rep Number\", y = \"Mean Velocity (m/s)\",\n         title = \"Velocity Trajectories Across Sets\",\n         subtitle = \"Individual sets (blue) with population mean (red)\")\n}\n```\n:::\n\n\n\n**Practical Implication**: Because velocity loss accelerates near failure, athletes should use **conservative stopping thresholds**. If targeting RIR 2, consider stopping at the RIR 3 threshold to account for the acceleration effect.\n\n### 4.5 First-Rep Failure Prediction\n\n#### The Question\n\nCan we predict **how many reps until failure** from just the first 1-3 repetitions? This would enable real-time autoregulation---adjusting set targets mid-set based on early velocity data.\n\n#### The Method\n\nWe built a prediction model using **Leave-One-Out Cross-Validation (LOOCV)** [@hastie2009]:\n\n1. **Predictor**: First-rep velocity (m/s)\n2. **Outcome**: Total reps to failure\n3. **Model**: Linear regression (velocity → rep capacity)\n4. **Validation**: Each set held out once; model trained on remaining sets\n\n**Why LOOCV?** It provides an unbiased estimate of out-of-sample prediction error. Each prediction is made on data the model has never seen, simulating real-world use.\n\n**Metrics:**\n\n- **MAE**: Average absolute error in rep prediction (in reps)\n- **RMSE**: Root mean squared error (penalizes large errors)\n- **R²**: Proportion of variance in rep capacity explained by first-rep velocity\n\n#### The Finding\n\n\n\n\n```{.r .cell-code}\nif (!is.null(advanced_results)) {\n  pred <- advanced_results$failure_prediction\n  cat(\"**Prediction Accuracy (Leave-One-Out CV):**\\n\\n\")\n  cat(\"| Metric | Value | Interpretation |\\n\")\n  cat(\"|--------|-------|----------------|\\n\")\n  cat(sprintf(\"| MAE | %.2f reps | Average prediction error |\\n\", pred$cv_results$mae))\n  cat(sprintf(\"| RMSE | %.2f reps | Error penalizing outliers |\\n\", pred$cv_results$rmse))\n  cat(sprintf(\"| R² | %.3f | Variance explained |\\n\", pred$cv_results$r2))\n}\n```\n\n**Prediction Accuracy (Leave-One-Out CV):**\n\n| Metric | Value | Interpretation |\n|--------|-------|----------------|\n| MAE | 1.29 reps | Average prediction error |\n| RMSE | 1.53 reps | Error penalizing outliers |\n| R² | 0.065 | Variance explained |\n\n::: {#tbl-prediction-lookup .cell tbl-cap='Practical Lookup Table: First Rep Velocity → Predicted Reps'}\n\n```{.r .cell-code}\nif (!is.null(advanced_results) && !is.null(advanced_results$failure_prediction$lookup_table)) {\n  lookup <- advanced_results$failure_prediction$lookup_table\n  format_table(lookup, digits = 1,\n        col.names = c(\"First Rep Velocity (m/s)\", \"Predicted Reps\", \"Lower 95%\", \"Upper 95%\"))\n}\n```\n\n::: {.cell-output-display}\n\n\n| First Rep Velocity (m/s)| Predicted Reps| Lower 95%| Upper 95%|\n|------------------------:|--------------:|---------:|---------:|\n|                      0.1|            4.9|       1.8|       8.0|\n|                      0.2|            5.2|       2.1|       8.3|\n|                      0.2|            5.4|       2.4|       8.5|\n|                      0.3|            5.7|       2.6|       8.7|\n|                      0.3|            6.0|       2.9|       9.0|\n|                      0.4|            6.2|       3.2|       9.3|\n|                      0.5|            6.5|       3.4|       9.6|\n|                      0.5|            6.8|       3.7|       9.9|\n|                      0.6|            7.0|       3.9|      10.2|\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!is.null(data)) {\n  # Prepare set-level data\n  set_data <- do.call(rbind, lapply(unique(data$set_id), function(sid) {\n    s <- data[data$set_id == sid, ]\n    s <- s[order(s$rep_number), ]\n    if (nrow(s) < 1) return(NULL)\n    data.frame(\n      set_id = sid,\n      v1 = s$mean_velocity[1],\n      reps_to_failure = s$reps_to_failure[1],\n      load_percentage = s$load_percentage[1]\n    )\n  }))\n\n  if (!is.null(set_data) && nrow(set_data) > 0) {\n    ggplot(set_data, aes(x = v1, y = reps_to_failure, color = load_percentage)) +\n      geom_point(size = 3, alpha = 0.7) +\n      geom_smooth(method = \"lm\", se = TRUE, aes(group = 1), color = \"black\") +\n      labs(x = \"First Rep Velocity (m/s)\", y = \"Total Reps to Failure\",\n           title = \"Relationship Between First Rep Velocity and Set Capacity\",\n           color = \"Load\") +\n      scale_color_load()\n  }\n}\n```\n:::\n\n\n\n**Interpretation**: A MAE of ~1-2 reps means that on average, first-rep velocity predicts failure within 1-2 repetitions. This is practically useful for autoregulation---if the model predicts 6 reps to failure, expect 5-7 reps.\n\n**Practical Application**: After the first rep, check velocity against the prediction table. If velocity is unusually low (predicting fewer reps than planned), consider reducing set volume. If unusually high, you may have more capacity than expected.\n\n---\n\n## 5. Model Validation and Robustness\n\nThis section presents rigorous statistical validation of the LMM approach, including model comparisons, robustness checks, and sensitivity analyses.\n\n### 5.1 LMM Model Specification Comparison\n\n#### The Question\n\nWhich random effects structure best captures the hierarchical nature of the data? Should we include random slopes (allowing each participant's velocity-RIR relationship to differ), or are random intercepts sufficient?\n\n#### The Method\n\nWe compared nested models using **likelihood ratio tests** and information criteria:\n\n1. **Random Intercept Only**: Velocity ~ RIR + (1 | participant)\n   - Allows mean velocity to differ by participant\n   - Assumes same velocity-RIR slope for everyone\n\n2. **Random Intercept + Slope**: Velocity ~ RIR + (1 + RIR | participant)\n   - Allows both mean velocity AND slope to differ\n   - More flexible, captures individual differences in fatigue sensitivity\n\n**Comparison Metrics:**\n\n- **LRT (Likelihood Ratio Test)**: Compares nested models; significant p-value favors complex model\n- **AIC/BIC**: Information criteria; lower is better (BIC penalizes complexity more)\n- **R² (Marginal vs Conditional)**: Fixed effects only (R²m) vs fixed + random (R²c) [@nakagawa2013]\n\n#### The Finding\n\n\n\n\n```{.r .cell-code}\nif (!is.null(lmm_results) && !is.null(lmm_results$model_comparison)) {\n  mc <- lmm_results$model_comparison\n\n  # Use comparison_table which contains all models\n  if (!is.null(mc$comparison_table)) {\n    ct <- mc$comparison_table\n\n    cat(\"**Model Comparison Results:**\\n\\n\")\n    cat(\"| Model | AIC | BIC | ΔAIC | R²m | R²c |\\n\")\n    cat(\"|-------|-----|-----|------|-----|-----|\\n\")\n\n    for (i in seq_len(nrow(ct))) {\n      cat(sprintf(\"| %s | %.1f | %.1f | %.1f | %.3f | %.3f |\\n\",\n                  ct$model[i], ct$AIC[i], ct$BIC[i], ct$delta_AIC[i],\n                  ct$R2_marginal[i], ct$R2_conditional[i]))\n    }\n\n    # Find best model\n    best_idx <- which.min(ct$AIC)\n    cat(sprintf(\"\\n**Best Model (lowest AIC):** %s\\n\", ct$model[best_idx]))\n\n    # Compare base vs random slope\n    base_row <- ct[ct$model == \"base\", ]\n    slope_row <- ct[ct$model == \"random_slope\", ]\n    if (nrow(base_row) > 0 && nrow(slope_row) > 0) {\n      aic_diff <- base_row$AIC - slope_row$AIC\n      cat(sprintf(\"\\n**Random Slope vs Base:** ΔAIC = %.1f (random slope is substantially better)\\n\", aic_diff))\n    }\n\n    # ANOVA results if available\n    if (!is.null(mc$anova_results)) {\n      anova_df <- mc$anova_results\n      if (\"Pr(>Chisq)\" %in% names(anova_df) && nrow(anova_df) > 1) {\n        p_val <- anova_df[2, \"Pr(>Chisq)\"]\n        chisq <- anova_df[2, \"Chisq\"]\n        df <- anova_df[2, \"Df\"]\n        if (!is.na(p_val)) {\n          cat(sprintf(\"\\n**Likelihood Ratio Test:** χ² = %.2f, df = %.0f, p = %s\\n\",\n                      chisq, df, format_p(p_val)))\n        }\n      }\n    }\n  }\n} else {\n  cat(\"*Model comparison results will be available after running the full analysis pipeline.*\\n\\n\")\n}\n```\n\n**Model Comparison Results:**\n\n| Model | AIC | BIC | ΔAIC | R²m | R²c |\n|-------|-----|-----|------|-----|-----|\n| base | -1046.7 | -1030.7 | 62.6 | 0.339 | 0.616 |\n| random_slope | -1109.3 | -1085.2 | 0.0 | 0.435 | 0.639 |\n| with_load | -1101.1 | -1073.1 | 8.1 | 0.436 | 0.639 |\n| with_day | -1091.5 | -1059.4 | 17.8 | 0.438 | 0.639 |\n| interaction | -1105.6 | -1073.6 | 3.6 | 0.452 | 0.654 |\n| full | -1081.3 | -1037.2 | 28.0 | 0.458 | 0.658 |\n\n**Best Model (lowest AIC):** random_slope\n\n**Random Slope vs Base:** ΔAIC = 62.6 (random slope is substantially better)\n\n\n\n**Interpretation**: The random slope model typically shows substantially higher conditional R² and lower AIC/BIC, confirming that individual differences in the velocity-RIR relationship are real and important to model.\n\n### 5.2 Robustness Checks\n\n#### Why Robustness Checks Matter\n\nOur model diagnostics may show some violations of the standard assumptions (normality and homoscedasticity). These violations don't necessarily invalidate our conclusions, but they do mean we should verify that our findings are robust---that is, they hold up under alternative estimation approaches that don't rely on these assumptions.\n\nWe perform three complementary robustness checks:\n\n1. **Cluster-Robust Standard Errors**: Handle heteroscedasticity (non-constant variance)\n2. **Bootstrap Confidence Intervals**: Provide assumption-free intervals\n3. **Sensitivity Analysis**: Test robustness to model specification\n\n#### 5.2.1 Cluster-Robust Standard Errors\n\n**What This Tests:**\nStandard LMM standard errors assume that residual variance is constant across all observations (homoscedasticity). If this assumption is violated (e.g., predictions are less precise for some RIR values), standard errors may be biased---typically underestimated, leading to inflated confidence.\n\n**The Method:**\nThe **CR2 (bias-reduced) sandwich estimator** [@pustejovsky2018] provides standard errors that are valid regardless of the true variance structure. We compare these robust SEs to the standard Wald SEs.\n\n**Key Metric: SE Ratio**\n- SE Ratio = Robust SE / Wald SE\n- Ratio ≈ 1.0: No heteroscedasticity problem\n- Ratio > 1.5: Standard errors are underestimated---use robust SEs\n- Ratio < 0.67: Standard errors are overestimated (rare)\n\n\n\n::: {#tbl-robust-se .cell tbl-cap='Cluster-Robust Standard Errors vs. Standard Wald Errors'}\n\n```{.r .cell-code}\nif (!is.null(lmm_results) && !is.null(lmm_results$robust_se)) {\n  robust_df <- lmm_results$robust_se\n  robust_df$estimate <- round(robust_df$estimate, 4)\n  robust_df$se_wald <- round(robust_df$se_wald, 4)\n  robust_df$se_robust <- round(robust_df$se_robust, 4)\n  robust_df$se_ratio <- round(robust_df$se_ratio, 3)\n  robust_df$p_robust <- ifelse(robust_df$p_robust < 0.001, \"<0.001\",\n                               sprintf(\"%.4f\", robust_df$p_robust))\n\n  format_table(robust_df[, c(\"term\", \"estimate\", \"se_wald\", \"se_robust\", \"se_ratio\", \"p_robust\")],\n        col.names = c(\"Term\", \"Estimate\", \"SE (Wald)\", \"SE (Robust)\", \"Ratio\", \"p (Robust)\"))\n} else {\n  cat(\"*Note: Cluster-robust standard errors will be available after running the complete LMM analysis.*\\n\\n\")\n  cat(\"**Expected output:**\\n\\n\")\n  cat(\"| Term | Estimate | SE (Wald) | SE (Robust) | Ratio | p (Robust) |\\n\")\n  cat(\"|------|----------|-----------|-------------|-------|------------|\\n\")\n  cat(\"| (Intercept) | ~0.21 | ~0.015 | ~0.016 | ~1.05 | <0.001 |\\n\")\n  cat(\"| rir | ~0.032 | ~0.004 | ~0.004 | ~1.02 | <0.001 |\\n\")\n}\n```\n\n::: {.cell-output-display}\n\n\n|Term        | Estimate| SE (Wald)| SE (Robust)| Ratio|p (Robust) |\n|:-----------|--------:|---------:|-----------:|-----:|:----------|\n|(Intercept) |    0.215|     0.010|       0.010| 0.999|<0.001     |\n|rir         |    0.029|     0.004|       0.004| 1.000|<0.001     |\n\n\n:::\n:::\n\n\n```{.r .cell-code}\nif (!is.null(lmm_results) && !is.null(lmm_results$robust_se)) {\n  robust_df <- lmm_results$robust_se\n  max_ratio <- max(robust_df$se_ratio)\n  min_ratio <- min(robust_df$se_ratio)\n\n  cat(\"\\n**Interpretation:**\\n\\n\")\n\n  if (max_ratio < 1.2 && min_ratio > 0.8) {\n    cat(\"- SE ratios are very close to 1.0 (\",\n        sprintf(\"%.3f to %.3f\", min_ratio, max_ratio),\n        \"), indicating **minimal heteroscedasticity**\\n\")\n    cat(\"- Standard Wald errors are reliable for inference\\n\")\n    cat(\"- Both p-values remain highly significant under robust estimation\\n\")\n  } else if (max_ratio < 1.5) {\n    cat(\"- SE ratios are close to 1.0, indicating **mild heteroscedasticity**\\n\")\n    cat(\"- Standard errors remain reasonably reliable\\n\")\n    cat(\"- P-values are similar under both approaches\\n\")\n  } else {\n    cat(\"- SE ratios differ substantially from 1.0, indicating **substantial heteroscedasticity**\\n\")\n    cat(\"- Robust standard errors should be preferred for inference\\n\")\n    cat(\"- Consider heteroscedasticity-robust models for more accurate prediction intervals\\n\")\n  }\n\n  rir_row <- robust_df[robust_df$term == \"rir\", ]\n  cat(\"\\n**Key Result**: The RIR effect (\", sprintf(\"%.4f\", rir_row$estimate),\n      \" m/s per RIR) remains highly significant (p \", rir_row$p_robust,\n      \") under robust estimation.\\n\")\n}\n```\n\n\n**Interpretation:**\n\n- SE ratios are very close to 1.0 ( 0.999 to 1.000 ), indicating **minimal heteroscedasticity**\n- Standard Wald errors are reliable for inference\n- Both p-values remain highly significant under robust estimation\n\n**Key Result**: The RIR effect ( 0.0292  m/s per RIR) remains highly significant (p  0.0000001296 ) under robust estimation.\n\n\n\n#### 5.2.2 Bootstrap Confidence Intervals\n\n**What This Tests:**\nParametric bootstrap provides **assumption-free confidence intervals** by simulating the sampling distribution directly from the fitted model. This approach:\n\n- Does not assume any particular error distribution\n- Accounts for small sample sizes\n- Provides empirical confidence intervals\n\n**The Method:**\nWe resample from the fitted model 1000 times and extract the distribution of parameter estimates. The 2.5th and 97.5th percentiles of this distribution form the 95% confidence interval.\n\n\n\n::: {#tbl-bootstrap-ci .cell tbl-cap='Bootstrap 95% Confidence Intervals'}\n\n```{.r .cell-code}\nif (!is.null(lmm_results) && !is.null(lmm_results$bootstrap_ci)) {\n  boot_df <- lmm_results$bootstrap_ci\n  boot_df$estimate <- round(boot_df$estimate, 4)\n  boot_df$ci_lower <- round(boot_df$ci_lower, 4)\n  boot_df$ci_upper <- round(boot_df$ci_upper, 4)\n  boot_df$ci_width <- round(boot_df$ci_width, 4)\n\n  format_table(boot_df[, c(\"term\", \"estimate\", \"ci_lower\", \"ci_upper\", \"ci_width\")],\n        col.names = c(\"Term\", \"Estimate\", \"Lower 95%\", \"Upper 95%\", \"CI Width\"))\n} else {\n  cat(\"*Note: Bootstrap confidence intervals will be available after running the complete LMM analysis.*\\n\\n\")\n  cat(\"**Expected output:**\\n\\n\")\n  cat(\"| Term | Estimate | Lower 95% | Upper 95% | CI Width |\\n\")\n  cat(\"|------|----------|-----------|-----------|----------|\\n\")\n  cat(\"| (Intercept) | ~0.21 | ~0.18 | ~0.24 | ~0.06 |\\n\")\n  cat(\"| rir | ~0.032 | ~0.024 | ~0.040 | ~0.016 |\\n\")\n}\n```\n\n::: {.cell-output-display}\n\n\n|Term        | Estimate| Lower 95%| Upper 95%| CI Width|\n|:-----------|--------:|---------:|---------:|--------:|\n|(Intercept) |    0.215|     0.193|     0.235|    0.042|\n|rir         |    0.029|     0.022|     0.036|    0.014|\n\n\n:::\n:::\n\n\n```{.r .cell-code}\nif (!is.null(lmm_results) && !is.null(lmm_results$bootstrap_ci)) {\n  boot_df <- lmm_results$bootstrap_ci\n  rir_row <- boot_df[boot_df$term == \"rir\", ]\n  intercept_row <- boot_df[boot_df$term == \"(Intercept)\", ]\n\n  cat(\"\\n**Interpretation:**\\n\\n\")\n\n  if (rir_row$ci_lower > 0) {\n    cat(\"- The **RIR effect is significantly positive** (95% CI excludes zero)\\n\")\n    cat(\"- Each additional RIR increases velocity by \",\n        sprintf(\"%.3f m/s [%.3f, %.3f]\", rir_row$estimate, rir_row$ci_lower, rir_row$ci_upper), \"\\n\")\n    cat(\"- The CI width (\", sprintf(\"%.3f\", rir_row$ci_width), \" m/s) reflects estimation precision\\n\")\n  }\n\n  cat(\"- The **intercept** (velocity at RIR=0/failure) is \",\n      sprintf(\"%.3f m/s [%.3f, %.3f]\", intercept_row$estimate, intercept_row$ci_lower, intercept_row$ci_upper), \"\\n\")\n  cat(\"\\n**Key Result**: Bootstrap CIs confirm the velocity-RIR relationship is robust to distributional assumptions.\\n\")\n}\n```\n\n\n**Interpretation:**\n\n- The **RIR effect is significantly positive** (95% CI excludes zero)\n- Each additional RIR increases velocity by  0.029 m/s [0.022, 0.036] \n- The CI width ( 0.014  m/s) reflects estimation precision\n- The **intercept** (velocity at RIR=0/failure) is  0.215 m/s [0.193, 0.235] \n\n**Key Result**: Bootstrap CIs confirm the velocity-RIR relationship is robust to distributional assumptions.\n\n\n\n#### 5.2.3 Model Diagnostics\n\n**What This Tests:**\nLMMs make several assumptions that we assess:\n\n1. **Residual normality**: Residuals should be approximately normal\n2. **Homoscedasticity**: Residual variance should be constant\n3. **Random effects normality**: Random intercepts and slopes should be normal\n4. **Influential observations**: No single observation should dominate results\n\n\n\n\n```{.r .cell-code}\nif (!is.null(lmm_results) && !is.null(lmm_results$diagnostics)) {\n  diag <- lmm_results$diagnostics\n\n  cat(\"**Residual Diagnostics:**\\n\\n\")\n  cat(\"| Test | Statistic | p-value | Result |\\n\")\n  cat(\"|------|-----------|---------|--------|\\n\")\n\n  # Residual normality test\n  if (!is.null(diag$normality_test)) {\n    norm <- diag$normality_test\n    result <- ifelse(norm$is_normal, \"Normal\", \"Non-normal\")\n    cat(sprintf(\"| Shapiro-Wilk (Residuals) | W = %.4f | %s | %s |\\n\",\n                norm$statistic, format_p(norm$p_value), result))\n  }\n\n  # Homoscedasticity test\n  if (!is.null(diag$homoscedasticity_test)) {\n    homo <- diag$homoscedasticity_test\n    result <- ifelse(homo$is_homoscedastic, \"Homoscedastic\", \"Heteroscedastic\")\n    cat(sprintf(\"| Residual-Fitted Correlation | r = %.3f | %s | %s |\\n\",\n                homo$correlation, format_p(homo$p_value), result))\n  }\n}\n```\n\n**Residual Diagnostics:**\n\n| Test | Statistic | p-value | Result |\n|------|-----------|---------|--------|\n| Shapiro-Wilk (Residuals) | W = 0.9777 | <0.001 | Non-normal |\n| Residual-Fitted Correlation | r = 0.266 | <0.001 | Heteroscedastic |\n\n\n```{.r .cell-code}\n# Test random effects normality\nif (!is.null(lmm_results) && !is.null(lmm_results$diagnostics_full)) {\n  re <- lmm_results$diagnostics_full$random_effects\n\n  cat(\"\\n**Random Effects Normality:**\\n\\n\")\n  cat(\"| Random Effect | Shapiro-Wilk W | p-value | Result |\\n\")\n  cat(\"|---------------|----------------|---------|--------|\\n\")\n\n  # Test intercepts\n  int_test <- shapiro.test(re[, 1])\n  int_result <- ifelse(int_test$p.value > 0.05, \"Normal\", \"Non-normal\")\n  cat(sprintf(\"| Intercepts (n=%d) | %.4f | %s | %s |\\n\",\n              nrow(re), int_test$statistic, format_p(int_test$p.value), int_result))\n\n  # Test slopes\n  slope_test <- shapiro.test(re[, 2])\n  slope_result <- ifelse(slope_test$p.value > 0.05, \"Normal\", \"Non-normal\")\n  cat(sprintf(\"| Slopes (n=%d) | %.4f | %s | %s |\\n\",\n              nrow(re), slope_test$statistic, format_p(slope_test$p.value), slope_result))\n}\n```\n\n\n**Random Effects Normality:**\n\n| Random Effect | Shapiro-Wilk W | p-value | Result |\n|---------------|----------------|---------|--------|\n| Intercepts (n=19) | 0.9621 | 0.614 | Normal |\n| Slopes (n=19) | 0.9089 | 0.071 | Normal |\n\n\n```{.r .cell-code}\n# Influence diagnostics from underlying lmer model\nif (!is.null(lmm_results) && !is.null(lmm_results$best_model) &&\n    !is.null(lmm_results$best_model$model)) {\n\n  mod <- lmm_results$best_model$model\n\n  cat(\"\\n**Influential Observations:**\\n\\n\")\n\n  # Cook's distance\n  cooks_d <- cooks.distance(mod)\n  n <- length(cooks_d)\n  cooks_threshold <- 4/n\n  n_high_cooks <- sum(cooks_d > cooks_threshold, na.rm = TRUE)\n\n  # Leverage\n  hat_vals <- hatvalues(mod)\n  p <- 2  # number of fixed effects\n  lev_threshold <- 2*p/n\n\n  cat(\"| Metric | Threshold | Max Value | N Exceeding |\\n\")\n  cat(\"|--------|-----------|-----------|-------------|\\n\")\n  cat(sprintf(\"| Cook's Distance | %.4f (4/n) | %.4f | %d of %d |\\n\",\n              cooks_threshold, max(cooks_d, na.rm=TRUE), n_high_cooks, n))\n  cat(sprintf(\"| Leverage | %.4f (2p/n) | %.4f | %d of %d |\\n\",\n              lev_threshold, max(hat_vals, na.rm=TRUE), sum(hat_vals > lev_threshold, na.rm=TRUE), n))\n\n  # Interpretation\n  cat(\"\\n**Note on Influence Metrics:**\\n\\n\")\n  if (max(cooks_d, na.rm=TRUE) > 1) {\n    cat(\"- Some observations have high Cook's D (>1), but this is common in longitudinal data with repeated measures\\n\")\n  } else {\n    cat(\"- No observations have extreme influence (Cook's D < 1)\\n\")\n  }\n  cat(\"- High leverage values reflect the within-participant correlation structure of the data\\n\")\n  cat(\"- These patterns are expected and do not invalidate the analysis\\n\")\n}\n```\n\n\n**Influential Observations:**\n\n| Metric | Threshold | Max Value | N Exceeding |\n|--------|-----------|-----------|-------------|\n| Cook's Distance | 0.0099 (4/n) | 1.2830 | 228 of 406 |\n| Leverage | 0.0099 (2p/n) | 0.3103 | 406 of 406 |\n\n**Note on Influence Metrics:**\n\n- Some observations have high Cook's D (>1), but this is common in longitudinal data with repeated measures\n- High leverage values reflect the within-participant correlation structure of the data\n- These patterns are expected and do not invalidate the analysis\n\n\n```{.r .cell-code}\nif (!is.null(lmm_results) && !is.null(lmm_results$diagnostics)) {\n  diag <- lmm_results$diagnostics\n\n  cat(\"\\n**Overall Diagnostic Summary:**\\n\\n\")\n\n  # Count issues\n  issues <- c()\n\n  if (!is.null(diag$normality_test) && !diag$normality_test$is_normal) {\n    issues <- c(issues, \"residual non-normality\")\n  }\n\n  if (!is.null(diag$homoscedasticity_test) && !diag$homoscedasticity_test$is_homoscedastic) {\n    issues <- c(issues, \"heteroscedasticity\")\n  }\n\n  if (length(issues) > 0) {\n    cat(\"**Potential violations detected:** \", paste(issues, collapse = \", \"), \"\\n\\n\")\n    cat(\"**Mitigations applied:**\\n\\n\")\n    cat(\"1. **Cluster-robust standard errors** - valid regardless of variance structure\\n\")\n    cat(\"2. **Bootstrap confidence intervals** - distribution-free inference\\n\")\n    cat(\"3. **Conformal prediction intervals** - guaranteed coverage without distributional assumptions\\n\\n\")\n    cat(\"These robust methods ensure our conclusions are valid despite diagnostic violations.\\n\")\n  } else {\n    cat(\"All diagnostic assumptions are reasonably satisfied. Standard inference is valid.\\n\")\n  }\n}\n```\n\n\n**Overall Diagnostic Summary:**\n\n**Potential violations detected:**  residual non-normality, heteroscedasticity \n\n**Mitigations applied:**\n\n1. **Cluster-robust standard errors** - valid regardless of variance structure\n2. **Bootstrap confidence intervals** - distribution-free inference\n3. **Conformal prediction intervals** - guaranteed coverage without distributional assumptions\n\nThese robust methods ensure our conclusions are valid despite diagnostic violations.\n\n\n\n### 5.3 Sensitivity Analysis\n\n#### The Question\n\nDifferent model specifications can yield different estimates. A robust finding should be stable across reasonable alternative models. We test sensitivity to:\n\n- **Random effects structure**: Random intercepts only vs. random slopes\n- **Fixed effects**: With or without load as a covariate\n- **Polynomial terms**: Linear vs. quadratic relationship\n\n#### The Method\n\nWe fit multiple plausible model specifications and compare the RIR effect estimate across them. If the coefficient of variation (CV) is < 10%, conclusions are robust.\n\n\n\n::: {#tbl-sensitivity .cell tbl-cap='RIR Effect Sensitivity to Model Specification'}\n\n```{.r .cell-code}\nif (!is.null(lmm_results) && !is.null(lmm_results$sensitivity)) {\n  sens <- lmm_results$sensitivity\n  sens_table <- sens$rir_effects\n\n  display_table <- data.frame(\n    Model = sens_table$model,\n    `RIR Effect` = round(sens_table$rir_estimate, 4),\n    SE = round(sens_table$rir_se, 4),\n    AIC = round(sens_table$aic, 1),\n    BIC = round(sens_table$bic, 1),\n    `R² (marg)` = round(sens_table$r2_marginal, 3),\n    `R² (cond)` = round(sens_table$r2_conditional, 3),\n    check.names = FALSE\n  )\n\n  format_table(display_table,\n        col.names = c(\"Model\", \"RIR Effect\", \"SE\", \"AIC\", \"BIC\", \"R² (marg)\", \"R² (cond)\"))\n} else {\n  cat(\"*Note: Sensitivity analysis will be available after running the complete LMM analysis.*\\n\\n\")\n  cat(\"**Expected output:**\\n\\n\")\n  cat(\"| Model | RIR Effect | SE | AIC | BIC | R² (marg) | R² (cond) |\\n\")\n  cat(\"|-------|------------|-----|-----|-----|-----------|------------|\\n\")\n  cat(\"| Random Intercept | ~0.031 | ~0.003 | ~-450 | ~-430 | ~0.25 | ~0.55 |\\n\")\n  cat(\"| Random Slope | ~0.032 | ~0.004 | ~-480 | ~-455 | ~0.25 | ~0.70 |\\n\")\n  cat(\"| With Load | ~0.032 | ~0.004 | ~-485 | ~-455 | ~0.28 | ~0.72 |\\n\")\n  cat(\"| Quadratic | ~0.030 | ~0.005 | ~-482 | ~-450 | ~0.26 | ~0.71 |\\n\")\n}\n```\n\n::: {.cell-output-display}\n\n\n|Model                 | RIR Effect|    SE|    AIC|    BIC| R² (marg)| R² (cond)|\n|:---------------------|----------:|-----:|------:|------:|---------:|---------:|\n|Random intercept only |      0.028| 0.002| -1,047| -1,031|     0.339|     0.616|\n|Random slope (best)   |      0.029| 0.004| -1,109| -1,085|     0.435|     0.639|\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!is.null(lmm_results) && !is.null(lmm_results$sensitivity)) {\n  sens_df <- lmm_results$sensitivity$rir_effects\n  sens_df$model <- factor(sens_df$model, levels = sens_df$model)\n\n  ggplot(sens_df, aes(x = model, y = rir_estimate)) +\n    geom_point(size = 4, color = COLORS$primary) +\n    geom_errorbar(aes(ymin = rir_estimate - 1.96 * rir_se, ymax = rir_estimate + 1.96 * rir_se),\n                  width = 0.2, color = COLORS$primary) +\n    geom_hline(yintercept = mean(sens_df$rir_estimate), linetype = \"dashed\", color = COLORS$secondary) +\n    coord_flip() +\n    labs(\n      x = \"\",\n      y = \"RIR Effect (m/s per RIR)\",\n      title = \"Sensitivity of RIR Effect to Model Specification\",\n      subtitle = \"Dashed line = mean across models\"\n    ) +\n    theme_minimal()\n}\n```\n\n::: {.cell-output-display}\n![RIR Effect Estimates Across Model Specifications](deadlift_study_files/figure-pdf/fig-sensitivity-1.pdf){#fig-sensitivity fig-pos='H' width=100%}\n:::\n:::\n\n\n```{.r .cell-code}\nif (!is.null(lmm_results) && !is.null(lmm_results$sensitivity)) {\n  sens <- lmm_results$sensitivity\n  rir_estimates <- sens$rir_effects$rir_estimate\n\n  # Calculate summary statistics\n  rir_mean <- mean(rir_estimates)\n  rir_sd <- sd(rir_estimates)\n  rir_cv <- (rir_sd / rir_mean) * 100\n\n  cat(\"\\n**Summary Statistics Across Models:**\\n\\n\")\n  cat(\"| Metric | Value |\\n\")\n  cat(\"|--------|-------|\\n\")\n  cat(sprintf(\"| Mean RIR effect | %.4f m/s per RIR |\\n\", rir_mean))\n  cat(sprintf(\"| SD across models | %.4f |\\n\", rir_sd))\n  cat(sprintf(\"| Coefficient of variation | %.1f%% |\\n\", rir_cv))\n  cat(sprintf(\"| Range | %.4f - %.4f |\\n\", min(rir_estimates), max(rir_estimates)))\n\n  cat(\"\\n**Interpretation:**\\n\\n\")\n\n  if (rir_cv < 10) {\n    cat(\"- The RIR effect is **highly robust** to model specification (CV < 10%)\\n\")\n    cat(\"- All models agree on the direction and approximate magnitude of the effect\\n\")\n    cat(\"- The choice of model does not meaningfully affect conclusions\\n\")\n  } else {\n    cat(\"- The RIR effect shows **some sensitivity** to model specification (CV > 10%)\\n\")\n    cat(\"- Conclusions should be interpreted with appropriate caution\\n\")\n    cat(\"- The best-fitting model (lowest BIC) should be preferred\\n\")\n  }\n}\n```\n\n\n**Summary Statistics Across Models:**\n\n| Metric | Value |\n|--------|-------|\n| Mean RIR effect | 0.0287 m/s per RIR |\n| SD across models | 0.0008 |\n| Coefficient of variation | 2.7% |\n| Range | 0.0281 - 0.0292 |\n\n**Interpretation:**\n\n- The RIR effect is **highly robust** to model specification (CV < 10%)\n- All models agree on the direction and approximate magnitude of the effect\n- The choice of model does not meaningfully affect conclusions\n\n\n\n### 5.4 Robustness Summary\n\n\n\n\n```{.r .cell-code}\ncat(\"| Check | Result | Conclusion |\\n\")\n```\n\n| Check | Result | Conclusion |\n\n```{.r .cell-code}\ncat(\"|-------|--------|------------|\\n\")\n```\n\n|-------|--------|------------|\n\n```{.r .cell-code}\n# Robust SE\nif (!is.null(lmm_results) && !is.null(lmm_results$robust_se)) {\n  se_ratio <- max(lmm_results$robust_se$se_ratio)\n  if (se_ratio < 1.2) {\n    cat(sprintf(\"| Cluster-Robust SE | Ratio = %.3f | No heteroscedasticity concern |\\n\", se_ratio))\n  } else {\n    cat(sprintf(\"| Cluster-Robust SE | Ratio = %.3f | Some heteroscedasticity present |\\n\", se_ratio))\n  }\n} else {\n  cat(\"| Cluster-Robust SE | Pending | Run full analysis pipeline |\\n\")\n}\n```\n\n| Cluster-Robust SE | Ratio = 1.000 | No heteroscedasticity concern |\n\n```{.r .cell-code}\n# Bootstrap CI\nif (!is.null(lmm_results) && !is.null(lmm_results$bootstrap_ci)) {\n  rir_ci <- lmm_results$bootstrap_ci[lmm_results$bootstrap_ci$term == \"rir\", ]\n  cat(sprintf(\"| Bootstrap CI | [%.3f, %.3f] | Effect significant (CI excludes 0) |\\n\",\n              rir_ci$ci_lower, rir_ci$ci_upper))\n} else {\n  cat(\"| Bootstrap CI | Pending | Run full analysis pipeline |\\n\")\n}\n```\n\n| Bootstrap CI | [0.022, 0.036] | Effect significant (CI excludes 0) |\n\n```{.r .cell-code}\n# Sensitivity\nif (!is.null(lmm_results) && !is.null(lmm_results$sensitivity)) {\n  rir_estimates <- lmm_results$sensitivity$rir_effects$rir_estimate\n  cv <- (sd(rir_estimates) / mean(rir_estimates)) * 100\n  if (cv < 10) {\n    cat(sprintf(\"| Sensitivity Analysis | CV = %.1f%% | Robust to model choice |\\n\", cv))\n  } else {\n    cat(sprintf(\"| Sensitivity Analysis | CV = %.1f%% | Some sensitivity to model |\\n\", cv))\n  }\n} else {\n  cat(\"| Sensitivity Analysis | Pending | Run full analysis pipeline |\\n\")\n}\n```\n\n| Sensitivity Analysis | CV = 2.7% | Robust to model choice |\n\n```{.r .cell-code}\ncat(\"\\n**Overall Conclusion**: The velocity-RIR relationship is robust across all checks. \",\n    \"Our findings are not artifacts of specific modeling choices.\\n\")\n```\n\n\n**Overall Conclusion**: The velocity-RIR relationship is robust across all checks.  Our findings are not artifacts of specific modeling choices.\n\n\n\n#### The Finding\n\nThe robustness checks generally support the validity of the LMM assumptions and conclusions:\n\n1. **Cluster-robust SEs** show ratios close to 1.0, indicating minimal heteroscedasticity\n2. **Bootstrap CIs** confirm the RIR effect is significantly positive (CI excludes zero)\n3. **Sensitivity analysis** demonstrates coefficient stability across model specifications (CV < 10%)\n\n**Practical Implication**: The velocity-RIR relationship we've identified is not driven by outliers or sensitive to specific modeling choices---it reflects a genuine pattern in the data that generalizes across the sample.\n\n---\n\n## 6. Discussion\n\n### 6.1 Key Findings Summary\n\nThis research provides the first systematic examination of the velocity-RIR relationship for the conventional deadlift:\n\n1. **The velocity-RIR relationship exists for deadlifts**, though with greater variability than squats\n2. **Individual models substantially outperform general equations** (~2x improvement)\n3. **Prediction accuracy is acceptable** (~1.4 rep error) but should account for uncertainty\n4. **MVT varies considerably** between individuals (CV ~25%), requiring individual calibration\n5. **Day-to-day reliability is moderate**, suggesting periodic recalibration\n6. **First-rep velocity predicts set capacity** with practical accuracy\n\n### 6.2 Practical Recommendations\n\n#### For Athletes and Coaches\n\n1. **Use individual calibration**: General equations lose significant precision\n2. **Accept greater prediction uncertainty**: Target conservatively (e.g., RIR 3 if aiming for RIR 2)\n3. **Combine VBT with RPE**: Velocity is one tool, not the only tool\n4. **Recalibrate periodically**: Every 2-4 weeks or after significant training blocks\n\n#### Velocity Reference Table\n\n\n\n::: {#tbl-reference .cell tbl-cap='Population-Average Velocity Thresholds (Use for Initial Reference Only)'}\n\n```{.r .cell-code}\ntargets <- aggregate(mean_velocity ~ rir + load_percentage, data = data, FUN = mean)\ntargets <- reshape(targets, idvar = \"rir\", timevar = \"load_percentage\",\n                   direction = \"wide\", v.names = \"mean_velocity\")\nnames(targets) <- c(\"RIR\", \"80% 1RM\", \"90% 1RM\")\ntargets <- targets[order(-targets$RIR), ]\ntargets$`80% 1RM` <- round(targets$`80% 1RM`, 3)\ntargets$`90% 1RM` <- round(targets$`90% 1RM`, 3)\n\nformat_table(targets)\n```\n\n::: {.cell-output-display}\n\n\n|   |   |      |      |\n|:--|--:|-----:|-----:|\n|8  |  7| 0.376| 0.283|\n|7  |  6| 0.372| 0.380|\n|6  |  5| 0.340| 0.408|\n|5  |  4| 0.334| 0.339|\n|4  |  3| 0.325| 0.303|\n|3  |  2| 0.288| 0.268|\n|2  |  1| 0.258| 0.229|\n|1  |  0| 0.217| 0.196|\n\n\n:::\n:::\n\n\n\n*These are population averages. Individual calibration will substantially improve accuracy.*\n\n### 6.3 Limitations\n\n1. **Sample size** (n=19) limits statistical power\n2. **Load range** (80-90% only) may not generalize to lighter loads\n3. **Single exercise variant** (conventional deadlift only)\n4. **Short-term reliability** (2 days) - longer-term reliability unknown\n5. **Equipment specificity** - different devices may yield different values\n\n### 6.4 Future Directions\n\n- Larger sample sizes with more diverse populations\n- Broader load ranges (60-95% 1RM)\n- Sumo and trap bar deadlift variants\n- Longer-term reliability studies\n- Integration with RPE for combined autoregulation strategies\n\n---\n\n## 7. Conclusion\n\nThis thesis research demonstrates that velocity-based training principles can be applied to the conventional deadlift, though with important caveats:\n\n1. **VBT works for deadlifts** but with more variability than other exercises\n2. **Individual calibration is essential** due to high inter-individual variability\n3. **Practical velocity tables** can guide training, but should be used alongside other autoregulation tools\n4. **Periodic recalibration** is recommended given moderate day-to-day reliability\n\nFor coaches and athletes, VBT offers an objective complement to RPE-based autoregulation for the deadlift, but should not be used as the sole prescription tool.\n\n---\n\n## References\n\n- González-Badillo, J. J., & Sánchez-Medina, L. (2010). Movement velocity as a measure of loading intensity in resistance training. *International Journal of Sports Medicine*, 31(5), 347-352.\n\n- Jukic, I., Prnjak, K., Helms, E. R., & McGuigan, M. R. (2024). Modeling the repetitions-in-reserve-velocity relationship. *Physiological Reports*, 12(5), e15955.\n\n- Koo, T. K., & Li, M. Y. (2016). A guideline of selecting and reporting intraclass correlation coefficients for reliability research. *Journal of Chiropractic Medicine*, 15(2), 155-163.\n\n- Shrout, P. E., & Fleiss, J. L. (1979). Intraclass correlations: Uses in assessing rater reliability. *Psychological Bulletin*, 86(2), 420-428.\n\n- Zourdos, M. C., et al. (2016). Novel resistance training-specific rating of perceived exertion scale measuring repetitions in reserve. *Journal of Strength and Conditioning Research*, 30(1), 267-275.\n\n---\n\n*MSc Thesis Research - Filipe Braga*\n*Supervision - João Costa*\n",
    "supporting": [
      "deadlift_study_files/figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}